#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç®€å•çš„æ•°æ®é›†å¯è§†åŒ–è„šæœ¬
ç”±äºGPUæ˜¾å­˜è¢«è®­ç»ƒå ç”¨,æˆ‘ä»¬å…ˆå¯è§†åŒ–æ•°æ®é›†çš„å›¾ç‰‡å’Œæ ‡æ³¨
"""

import os
import json
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

def visualize_dataset_samples(data_root, num_samples=10, output_dir='dataset_visualization'):
    """
    å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½annotations
    ann_file = Path(data_root) / 'annotations.json'
    with open(ann_file, 'r', encoding='utf-8') as f:
        annotations = json.load(f)
    
    print(f"æ•°æ®é›†æ€»æ ·æœ¬æ•°: {len(annotations)}")
    print(f"å¯è§†åŒ–å‰ {num_samples} ä¸ªæ ·æœ¬\n")
    
    # é€‰æ‹©å‰Nä¸ªæ ·æœ¬
    samples = annotations[:num_samples]
    
    results = []
    
    for idx, sample in enumerate(samples):
        print(f"[{idx+1}/{num_samples}] å¤„ç†æ ·æœ¬...")
        
        # è·å–å›¾ç‰‡è·¯å¾„
        image_path = Path(data_root) / 'images' / sample['image']
        if not image_path.exists():
            print(f"  âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            continue
        
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        img_array = np.array(image)
        
        # è·å–æ ‡æ³¨ä¿¡æ¯
        text_labels = sample.get('text', [])
        masks = sample.get('mask', [])
        
        # æ„å»ºé—®é¢˜å’Œç­”æ¡ˆ
        if text_labels:
            question = f"è¯·åˆ†å‰²å›¾åƒä¸­çš„{', '.join(text_labels)}"
            answer = f"å›¾åƒä¸­åŒ…å« {len(masks)} ä¸ª{text_labels[0]}åŒºåŸŸ"
        else:
            question = "è¯·åˆ†å‰²å›¾åƒä¸­çš„ç›®æ ‡"
            answer = f"å›¾åƒä¸­åŒ…å« {len(masks)} ä¸ªç›®æ ‡åŒºåŸŸ"
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(16, 8))
        
        # å·¦ä¾§: åŸå›¾
        axes[0].imshow(img_array)
        axes[0].set_title(f'åŸå§‹å›¾ç‰‡\n{Path(image_path).name}', fontsize=10)
        axes[0].axis('off')
        
        # å³ä¾§: æ ‡æ³¨ä¿¡æ¯
        axes[1].axis('off')
        info_text = f"""
æ ·æœ¬ #{idx+1}

å›¾ç‰‡: {Path(image_path).name}
å°ºå¯¸: {img_array.shape[1]} x {img_array.shape[0]}

é—®é¢˜:
{question[:200]}...

ç­”æ¡ˆ:
{answer[:200]}...

æ©ç æ•°é‡: {len(sample.get('masks', []))}
        """
        axes[1].text(0.1, 0.5, info_text, 
                    fontsize=11, 
                    verticalalignment='center',
                    family='monospace',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_file = output_path / f'sample_{idx+1:03d}.png'
        plt.savefig(output_file, dpi=100, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… å·²ä¿å­˜: {output_file}")
        
        results.append({
            'sample_id': idx + 1,
            'image': str(image_path.name),
            'image_size': f"{img_array.shape[1]}x{img_array.shape[0]}",
            'num_masks': len(sample.get('masks', [])),
            'question_preview': question[:100],
            'answer_preview': answer[:100],
        })
    
    # ä¿å­˜æ‘˜è¦
    summary_file = output_path / 'summary.json'
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å¯è§†åŒ–å®Œæˆ!")
    print(f"ğŸ“Š è¾“å‡ºç›®å½•: {output_path}")
    print(f"ğŸ“„ æ‘˜è¦æ–‡ä»¶: {summary_file}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  - æ€»æ ·æœ¬æ•°: {len(annotations)}")
    print(f"  - å·²å¯è§†åŒ–: {len(results)}")
    if results:
        avg_masks = sum(r['num_masks'] for r in results) / len(results)
        print(f"  - å¹³å‡æ©ç æ•°: {avg_masks:.2f}")

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–è¡€ç®¡åˆ†å‰²æ•°æ®é›†')
    parser.add_argument('--data-root', type=str, 
                       default='/home/ubuntu/Sa2VA/data/vessel_data',
                       help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--num-samples', type=int, default=10,
                       help='å¯è§†åŒ–æ ·æœ¬æ•°é‡')
    parser.add_argument('--output-dir', type=str, default='dataset_visualization',
                       help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    visualize_dataset_samples(
        data_root=args.data_root,
        num_samples=args.num_samples,
        output_dir=args.output_dir
    )
