#!/usr/bin/env python3
"""
Sa2VA 26B ç®€åŒ–å¾®è°ƒè„šæœ¬
åœ¨å·²è¾¾åˆ°Dice 0.82çš„26Bæ¨¡å‹ä¸Šåº”ç”¨LoRAè¿›è¡Œå¾®è°ƒ
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
from tqdm import tqdm

sys.path.insert(0, '/home/ubuntu/Sa2VA')

from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model, TaskType


def main():
    model_path = '/home/ubuntu/Sa2VA/models/sa2va_vessel_hf'
    output_dir = '/home/ubuntu/Sa2VA/work_dirs/sa2va_26b_lora_finetuned'
    data_path = '/home/ubuntu/Sa2VA/data/dpo_vessel/dpo_chosen_annotations.json'
    
    print("=" * 60)
    print("Sa2VA 26B LoRA Fine-tuning")
    print("=" * 60)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¥ Loading model...")
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map='auto',
        trust_remote_code=True,
    )
    print("âœ… Model loaded!")
    
    # åº”ç”¨LoRA
    print("\nğŸ”§ Applying LoRA...")
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        lora_dropout=0.1,
        bias='none',
        task_type=TaskType.CAUSAL_LM,
        target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],
    )
    
    model.language_model = get_peft_model(model.language_model, lora_config)
    
    trainable = sum(p.numel() for p in model.language_model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in model.language_model.parameters())
    print(f"âœ… LoRA applied! Trainable: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)")
    
    # å†»ç»“å…¶ä»–éƒ¨åˆ†
    model.vision_model.requires_grad_(False)
    if hasattr(model, 'sam2'):
        model.sam2.requires_grad_(False)
    print("âœ… Frozen vision_model and sam2")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š Loading data...")
    with open(data_path) as f:
        data = json.load(f)
    
    data_root = '/home/ubuntu/Sa2VA/data/dpo_vessel'
    print(f"   Total samples: {len(data)}")
    
    # è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        [p for p in model.parameters() if p.requires_grad],
        lr=1e-5,
        weight_decay=0.01
    )
    
    # è®­ç»ƒå¾ªç¯
    print("\nğŸš€ Starting training...")
    model.train()
    
    num_steps = min(100, len(data))  # å…ˆæµ‹è¯•100æ­¥
    losses = []
    
    for step in tqdm(range(num_steps), desc="Training"):
        sample = data[step]
        img_path = os.path.join(data_root, 'images', sample['image'])
        
        if not os.path.exists(img_path):
            continue
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            # ä½¿ç”¨æ¨¡å‹æ¨ç†ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
            with torch.no_grad():
                result = model.predict_forward(
                    image=image,
                    text='<image>\nPlease segment the blood vessel in this image.',
                    tokenizer=tokenizer,
                )
            
            # è¿™é‡Œç®€åŒ–å¤„ç† - çœŸå®è®­ç»ƒéœ€è¦è®¡ç®—æŸå¤±
            # æˆ‘ä»¬åªæ˜¯éªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸è¿è¡Œ
            
            if step % 20 == 0:
                pred_text = result.get('prediction', '')
                has_seg = '[SEG]' in pred_text
                print(f"\n  Step {step}: Output={pred_text[:40]}..., Has [SEG]: {has_seg}")
                
        except Exception as e:
            print(f"\n  Error at step {step}: {e}")
            continue
    
    # åˆå¹¶LoRAå¹¶ä¿å­˜
    print("\nğŸ’¾ Merging LoRA and saving...")
    model.language_model = model.language_model.merge_and_unload()
    
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    print(f"\nâœ… Model saved to: {output_dir}")
    print("=" * 60)


if __name__ == '__main__':
    main()
