---
language: en
license: apache-2.0
tags:
- medical-imaging
- vessel-segmentation
- oct
- multimodal
- vision-language
- sa2va
- internvl
- sam2
datasets:
- custom-oct-vessel
metrics:
- iou
- dice
- precision
- recall
library_name: transformers
pipeline_tag: image-segmentation
---

# Sa2VA: Segment Anything to Vessel Analysis

<div align="center">
  <img src="https://img.shields.io/badge/Task-Vessel%20Segmentation-blue" alt="Task"/>
  <img src="https://img.shields.io/badge/Model-Vision--Language-green" alt="Model"/>
  <img src="https://img.shields.io/badge/Data-OCT-orange" alt="Data"/>
</div>

## æ¨¡å‹æè¿°

Sa2VAï¼ˆSegment Anything to Vessel Analysisï¼‰æ˜¯ä¸€ä¸ªåˆ›æ–°çš„å¤šæ¨¡æ€è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºåŒ»å­¦å›¾åƒä¸­çš„è¡€ç®¡åˆ†å‰²ä»»åŠ¡ã€‚è¯¥æ¨¡å‹å°†å¤§è§„æ¨¡é¢„è®­ç»ƒçš„InternVL-8Bä¸ä¸“ä¸šåˆ†å‰²æ¨¡å‹SAM2-Largeç›¸ç»“åˆï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’å®ç°é«˜ç²¾åº¦çš„è‡ªåŠ¨åˆ†å‰²ã€‚

## æ¨¡å‹è¯¦æƒ…

- **å¼€å‘è€…**: qimingfan10
- **æ¨¡å‹ç±»å‹**: å¤šæ¨¡æ€è§†è§‰-è¯­è¨€åˆ†å‰²æ¨¡å‹
- **æ¶æ„**: InternVL-8B (Vision-Language) + SAM2-Large (Segmentation)
- **å‚æ•°é‡**: ~14B
- **è®­ç»ƒæ•°æ®**: 9,346å¼ OCTè§†ç½‘è†œè¡€ç®¡å›¾åƒ
- **ä»»åŠ¡**: åŒ»å­¦å›¾åƒè¡€ç®¡åˆ†å‰²

## æ€§èƒ½æŒ‡æ ‡

åœ¨OCTè§†ç½‘è†œè¡€ç®¡æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| IoU (Intersection over Union) | 0.6725 |
| Diceç³»æ•° | 0.8005 |
| Precision | 0.8659 |
| Recall | 0.7539 |
| Accuracy | 0.9784 |

## ä½¿ç”¨æ–¹æ³•

### å®‰è£…ä¾èµ–

```bash
pip install torch>=2.1.0 transformers>=4.37.0 pillow opencv-python
```

### åŸºç¡€æ¨ç†

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image
import torch

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "qimingfan10/sa2va-vessel-hf",
    torch_dtype="auto",
    device_map="auto",
    trust_remote_code=True,
    low_cpu_mem_usage=True
)

tokenizer = AutoTokenizer.from_pretrained(
    "qimingfan10/sa2va-vessel-hf",
    trust_remote_code=True
)

model.eval()

# å‡†å¤‡å›¾åƒ
image = Image.open("your_oct_image.jpg").convert('RGB')

# æ„å»ºprompt
text = "<image>Please segment the blood vessel."

# æ¨ç†
with torch.no_grad():
    result = model.predict_forward(
        image=image,
        text=text,
        tokenizer=tokenizer,
        processor=None
    )

# è·å–åˆ†å‰²æ©ç 
prediction_masks = result['prediction_masks']
pred_mask = prediction_masks[0][0]  # (H, W)

# ä¿å­˜ç»“æœ
import cv2
import numpy as np

if isinstance(pred_mask, torch.Tensor):
    pred_mask = pred_mask.cpu().numpy()

# äºŒå€¼åŒ–
pred_mask_binary = (pred_mask > 0.5).astype(np.uint8) * 255

# ä¿å­˜
cv2.imwrite("segmentation_result.png", pred_mask_binary)
```

### é«˜çº§ç”¨æ³•ï¼šè‡ªå®šä¹‰prompt

```python
# ç»†åŒ–åˆ†å‰²
text = "<image>Please segment the retinal arteries only."

# å¤šåŒºåŸŸåˆ†å‰²
text = "<image>Segment the blood vessel. [SEG] Also segment the optic disc. [SEG]"

# æ’é™¤åŒºåŸŸ
text = "<image>Segment vessels but exclude the fovea region."
```

## è®­ç»ƒè¯¦æƒ…

### è®­ç»ƒé…ç½®

- **ä¼˜åŒ–å™¨**: AdamW
- **å­¦ä¹ ç‡**: 2e-5 (warmup 366æ­¥)
- **Batch Size**: 16 (4 per GPU Ã— 4 GPUs)
- **Gradient Accumulation**: 2
- **Effective Batch Size**: 32
- **è¿­ä»£æ¬¡æ•°**: 12,192
- **è®­ç»ƒæ—¶é—´**: ~72å°æ—¶
- **ç¡¬ä»¶**: 4Ã— NVIDIA RTX A6000 (48GB)

### æŸå¤±å‡½æ•°

```
L_total = L_BCE + L_Dice + 0.5 Ã— L_Language

- L_BCE: Binary Cross-Entropy (åƒç´ çº§ç›‘ç£)
- L_Dice: Dice Loss (å¤„ç†ç±»åˆ«ä¸å¹³è¡¡)
- L_Language: Cross-Entropy (ä¿æŒè¯­è¨€ç†è§£èƒ½åŠ›)
```

### å‚æ•°å†»ç»“ç­–ç•¥

- Vision Encoder (InternViT-6B): å®Œå…¨å†»ç»“
- LLMå‰30å±‚: å†»ç»“
- LLMå10å±‚: éƒ¨åˆ†å¾®è°ƒ
- Projector (2-layer MLP): ä»å¤´è®­ç»ƒ
- SAM2 Decoder: å®Œå…¨å¾®è°ƒ

å¯è®­ç»ƒå‚æ•°çº¦å 15% (~1.2B / 8B)

## æ•°æ®é›†

- **æ¥æº**: å¤šä¸­å¿ƒä¸´åºŠé‡‡é›†çš„OCTå›¾åƒ
- **å›¾åƒæ•°é‡**: 9,346å¼ 
- **åˆ†è¾¨ç‡**: 512Ã—512 - 1024Ã—1024
- **æ ‡æ³¨æ–¹å¼**: ä¸“ä¸šåŒ»å¸ˆæ‰‹å·¥æ ‡æ³¨å¤šè¾¹å½¢mask
- **åˆ’åˆ†**: è®­ç»ƒ90% / éªŒè¯5% / æµ‹è¯•5%

## å±€é™æ€§

1. **è®¡ç®—æˆæœ¬**: éœ€è¦é«˜æ€§èƒ½GPUï¼ˆæ¨è24GB+ VRAMï¼‰
2. **æ¨ç†é€Ÿåº¦**: çº¦4.5ç§’/å¸§ï¼ˆå•GPUï¼‰ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨
3. **æ•°æ®ä¾èµ–**: éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒ
4. **æ³›åŒ–èƒ½åŠ›**: ä¸»è¦åœ¨OCTæ•°æ®ä¸Šè®­ç»ƒï¼Œè·¨æ¨¡æ€æ³›åŒ–æœ‰é™

## ä¼¦ç†è€ƒé‡

- æœ¬æ¨¡å‹ä»…ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸åº”ç›´æ¥ç”¨äºä¸´åºŠè¯Šæ–­
- åŒ»å­¦å›¾åƒåˆ†å‰²ç»“æœåº”ç”±ä¸“ä¸šåŒ»å¸ˆå®¡æ ¸
- æ¨¡å‹å¯èƒ½åœ¨æœªè§è¿‡çš„æ•°æ®åˆ†å¸ƒä¸Šè¡¨ç°ä¸ä½³

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æ­¤æ¨¡å‹ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{sa2va2024,
  title={Sa2VA: Segment Anything to Vessel Analysis},
  author={Qiming Fan},
  year={2024},
  publisher={HuggingFace},
  howpublished={\url{https://huggingface.co/qimingfan10/sa2va-vessel-hf}}
}
```

## è®¸å¯è¯

Apache 2.0

## ç›¸å…³èµ„æº

- ğŸ“„ [æ–¹æ³•è®ºæ–‡æ¡£](https://github.com/qimingfan10/RLSa2va/blob/main/SA2VA_METHODOLOGY.md)
- ğŸ”§ [æŠ€æœ¯ç»†èŠ‚](https://github.com/qimingfan10/RLSa2va/blob/main/SA2VA_TECHNICAL_DETAILS.md)
- ğŸ™ [GitHubä»“åº“](https://github.com/qimingfan10/RLSa2va)
- ğŸ“š [å®Œæ•´æ–‡æ¡£](https://github.com/qimingfan10/RLSa2va/blob/main/DOCUMENTATION_INDEX.md)

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- GitHub Issues: https://github.com/qimingfan10/RLSa2va/issues
- HuggingFace Discussions: https://huggingface.co/qimingfan10/sa2va-vessel-hf/discussions
