#!/usr/bin/env python3
"""
å°†DPOè®­ç»ƒçš„LoRAæƒé‡åº”ç”¨åˆ°HuggingFaceæ¨¡å‹
"""

import os
import sys
import torch
import shutil
from pathlib import Path

sys.path.insert(0, '/home/ubuntu/Sa2VA')

def apply_dpo_lora(base_hf_path, dpo_checkpoint_path, output_path):
    """å°†DPO LoRAæƒé‡åº”ç”¨åˆ°HFæ¨¡å‹"""
    from transformers import AutoModelForCausalLM, AutoTokenizer
    from safetensors.torch import save_file, load_file
    
    print("=" * 60)
    print("ğŸ”§ åº”ç”¨DPO LoRAæƒé‡")
    print("=" * 60)
    
    # åŠ è½½DPO checkpoint
    print(f"\nğŸ“¥ åŠ è½½DPO checkpoint: {dpo_checkpoint_path}")
    dpo_ckpt = torch.load(dpo_checkpoint_path, map_location='cpu', weights_only=False)
    dpo_state = dpo_ckpt.get('state_dict', dpo_ckpt)
    
    # ç»Ÿè®¡LoRAå‚æ•°
    lora_params = {k: v for k, v in dpo_state.items() if 'lora' in k.lower()}
    print(f"   DPO LoRAå‚æ•°: {len(lora_params)}")
    
    # åŠ è½½åŸºç¡€HFæ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½åŸºç¡€æ¨¡å‹: {base_hf_path}")
    model = AutoModelForCausalLM.from_pretrained(
        base_hf_path,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True
    )
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_path, exist_ok=True)
    
    # å¤åˆ¶åŸºç¡€æ¨¡å‹æ–‡ä»¶
    print(f"\nğŸ“‹ å¤åˆ¶åŸºç¡€æ¨¡å‹æ–‡ä»¶...")
    for f in os.listdir(base_hf_path):
        src = os.path.join(base_hf_path, f)
        dst = os.path.join(output_path, f)
        if os.path.isfile(src) and not f.endswith('.safetensors'):
            shutil.copy2(src, dst)
    
    # è·å–æ¨¡å‹state_dict
    model_state = model.state_dict()
    
    # æ˜ å°„DPOå‚æ•°ååˆ°HFå‚æ•°å
    # DPOæ ¼å¼: mllm.model.language_model.base_model.model.xxx
    # HFæ ¼å¼: language_model.model.xxx
    
    print(f"\nğŸ”€ åº”ç”¨LoRAæƒé‡ (æ‰‹åŠ¨åˆå¹¶)...")
    
    # LoRAé…ç½®
    lora_alpha = 128  # ä»é…ç½®ä¸­è·å–
    lora_r = 64
    scaling = lora_alpha / lora_r
    
    # æ”¶é›†LoRA Aå’ŒBçŸ©é˜µ
    lora_pairs = {}  # {base_key: {'A': tensor, 'B': tensor}}
    
    for dpo_key, dpo_value in lora_params.items():
        # è§£ækey: mllm.model.language_model.base_model.model.model.layers.X.xxx.lora_A.default.weight
        if 'lora_A' in dpo_key:
            base_key = dpo_key.replace('.lora_A.default.weight', '')
            if base_key not in lora_pairs:
                lora_pairs[base_key] = {}
            lora_pairs[base_key]['A'] = dpo_value
        elif 'lora_B' in dpo_key:
            base_key = dpo_key.replace('.lora_B.default.weight', '')
            if base_key not in lora_pairs:
                lora_pairs[base_key] = {}
            lora_pairs[base_key]['B'] = dpo_value
    
    print(f"   æ‰¾åˆ° {len(lora_pairs)} ä¸ªLoRAå±‚å¯¹")
    
    # åˆå¹¶LoRAåˆ°åŸºç¡€æƒé‡
    applied = 0
    for base_key, lora_dict in lora_pairs.items():
        if 'A' not in lora_dict or 'B' not in lora_dict:
            continue
        
        # è½¬æ¢keyåˆ°HFæ ¼å¼
        # mllm.model.language_model.base_model.model.model.layers.X.xxx
        # -> language_model.model.layers.X.xxx
        hf_key = base_key
        
        # ç§»é™¤PEFTå‰ç¼€
        if '.base_model.model.' in hf_key:
            hf_key = hf_key.replace('.base_model.model.', '.')
        
        # ç§»é™¤mllmå‰ç¼€
        if hf_key.startswith('mllm.model.'):
            hf_key = hf_key[len('mllm.model.'):]
        
        # æ·»åŠ .weightåç¼€
        hf_key = hf_key + '.weight'
        
        if hf_key in model_state:
            # W' = W + B @ A * scaling
            lora_A = lora_dict['A'].float()
            lora_B = lora_dict['B'].float()
            delta = (lora_B @ lora_A) * scaling
            
            original = model_state[hf_key].float()
            if delta.shape == original.shape:
                model_state[hf_key] = (original + delta).to(torch.bfloat16)
                applied += 1
            else:
                print(f"   å½¢çŠ¶ä¸åŒ¹é…: {hf_key} - delta {delta.shape} vs orig {original.shape}")
        else:
            # å°è¯•å»æ‰ä¸€å±‚model
            alt_key = hf_key.replace('language_model.model.model.', 'language_model.model.')
            if alt_key in model_state:
                lora_A = lora_dict['A'].float()
                lora_B = lora_dict['B'].float()
                delta = (lora_B @ lora_A) * scaling
                original = model_state[alt_key].float()
                if delta.shape == original.shape:
                    model_state[alt_key] = (original + delta).to(torch.bfloat16)
                    applied += 1
    
    print(f"   æˆåŠŸåˆå¹¶: {applied}/{len(lora_pairs)} LoRAå±‚")
    
    # åŠ è½½æ›´æ–°åçš„æƒé‡
    model.load_state_dict(model_state, strict=False)
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {output_path}")
    model.save_pretrained(output_path, safe_serialization=True)
    
    # å¤åˆ¶tokenizer
    tokenizer = AutoTokenizer.from_pretrained(base_hf_path, trust_remote_code=True)
    tokenizer.save_pretrained(output_path)
    
    print(f"\nâœ… å®Œæˆ! æ¨¡å‹ä¿å­˜åœ¨: {output_path}")
    
    return output_path

def test_model(model_path, test_image):
    """æµ‹è¯•æ¨¡å‹"""
    from PIL import Image
    from transformers import AutoModelForCausalLM, AutoTokenizer
    
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True
    ).cuda().eval()
    
    image = Image.open(test_image).convert('RGB')
    prompt = '<image>\nPlease segment the blood vessel in this image.'
    
    with torch.no_grad():
        result = model.predict_forward(
            image=image,
            text=prompt,
            tokenizer=tokenizer,
        )
    
    print(f"   è¾“å‡º: {result['prediction']}")
    print(f"   æœ‰mask: {len(result.get('prediction_masks', [])) > 0}")

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--base_model', default='/home/ubuntu/Sa2VA/work_dirs/vessel_segmentation/iter_12192_hf')
    parser.add_argument('--dpo_checkpoint', default='/home/ubuntu/Sa2VA/work_dirs/dpo_vessel_training/iter_1224.pth')
    parser.add_argument('--output', default='/home/ubuntu/Sa2VA/work_dirs/dpo_vessel_training/dpo_model_hf')
    parser.add_argument('--test', action='store_true')
    args = parser.parse_args()
    
    output_path = apply_dpo_lora(args.base_model, args.dpo_checkpoint, args.output)
    
    if args.test:
        test_image = '/home/ubuntu/Sa2VA/data/dpo_vessel/images/An Cong Xue(0000932433)_1-3_1_051C3E6A_frame_000011.jpg'
        test_model(output_path, test_image)

if __name__ == '__main__':
    main()
