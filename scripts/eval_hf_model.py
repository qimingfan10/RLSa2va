#!/usr/bin/env python3
"""
ä½¿ç”¨HuggingFaceæ ¼å¼æ¨¡å‹è¯„ä¼°è¡€ç®¡åˆ†å‰²æ•ˆæœ
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
from pathlib import Path
from tqdm import tqdm

sys.path.insert(0, '/home/ubuntu/Sa2VA')

def calculate_iou(pred_mask, gt_mask):
    """è®¡ç®—IoU"""
    pred = (pred_mask > 0.5).astype(float)
    gt = (gt_mask > 127).astype(float)
    intersection = (pred * gt).sum()
    union = pred.sum() + gt.sum() - intersection
    return intersection / (union + 1e-8)

def calculate_dice(pred_mask, gt_mask):
    """è®¡ç®—Dice"""
    pred = (pred_mask > 0.5).astype(float)
    gt = (gt_mask > 127).astype(float)
    intersection = (pred * gt).sum()
    return 2 * intersection / (pred.sum() + gt.sum() + 1e-8)

def load_model(model_path):
    """åŠ è½½HuggingFaceæ¨¡å‹"""
    from transformers import AutoModelForCausalLM, AutoTokenizer
    
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    
    # å•GPUåŠ è½½
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True
    ).cuda()
    model.eval()
    
    print(f"   âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return model, tokenizer

def inference(model, tokenizer, image_path, prompt="<image>\nPlease segment the blood vessel in this image."):
    """æ¨ç†"""
    image = Image.open(image_path).convert('RGB')
    
    with torch.no_grad():
        result = model.predict_forward(
            image=image,
            text=prompt,
            tokenizer=tokenizer,
        )
    
    return {
        'text': result.get('prediction', ''),
        'masks': result.get('prediction_masks', []),
    }

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', default='/home/ubuntu/Sa2VA/work_dirs/vessel_segmentation/iter_12192_hf')
    parser.add_argument('--num_samples', type=int, default=20)
    parser.add_argument('--output_dir', default='/home/ubuntu/Sa2VA/work_dirs/eval_results')
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ§ª è¡€ç®¡åˆ†å‰²æ¨¡å‹è¯„ä¼°")
    print("=" * 60)
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    model, tokenizer = load_model(args.model_path)
    
    # åŠ è½½DPOæµ‹è¯•æ•°æ®
    ann_path = '/home/ubuntu/Sa2VA/data/dpo_vessel/dpo_annotations.json'
    with open(ann_path) as f:
        annotations = json.load(f)
    
    # éšæœºé‡‡æ ·
    import random
    random.seed(42)
    samples = random.sample(annotations, min(args.num_samples, len(annotations)))
    
    print(f"\nğŸ“¸ è¯„ä¼° {len(samples)} å¼ å›¾ç‰‡...")
    
    results = []
    seg_success = 0
    
    for i, ann in enumerate(tqdm(samples, desc="æ¨ç†ä¸­")):
        img_path = os.path.join('/home/ubuntu/Sa2VA/data/dpo_vessel', ann['image'])
        if not os.path.exists(img_path):
            continue
        
        try:
            result = inference(model, tokenizer, img_path)
            has_seg = '[SEG]' in result['text']
            has_mask = len(result['masks']) > 0
            
            if has_seg and has_mask:
                seg_success += 1
                
                # è®¡ç®—ä¸chosen/rejectedçš„IoUå¯¹æ¯”
                pred_mask = result['masks'][0]
                if len(pred_mask.shape) == 3:
                    pred_mask = pred_mask[0]
                if isinstance(pred_mask, torch.Tensor):
                    pred_mask = pred_mask.cpu().numpy()
                
                # åŠ è½½chosen maskä½œä¸ºå‚è€ƒ
                chosen_path = os.path.join('/home/ubuntu/Sa2VA/data/dpo_vessel', ann['chosen_mask'])
                if os.path.exists(chosen_path):
                    chosen_mask = np.array(Image.open(chosen_path).convert('L'))
                    # éœ€è¦resize pred_maskåˆ°ç›¸åŒå°ºå¯¸
                    pred_resized = np.array(Image.fromarray((pred_mask * 255).astype(np.uint8)).resize(
                        (chosen_mask.shape[1], chosen_mask.shape[0]), Image.NEAREST)) / 255.0
                    iou_with_chosen = calculate_iou(pred_resized, chosen_mask)
                else:
                    iou_with_chosen = None
            else:
                iou_with_chosen = None
            
            results.append({
                'image': ann['image'],
                'has_seg': has_seg,
                'has_mask': has_mask,
                'text': result['text'][:100],
                'chosen_iou': ann['chosen_iou'],
                'rejected_iou': ann['rejected_iou'],
                'pred_iou_with_chosen': iou_with_chosen,
            })
            
        except Exception as e:
            print(f"\n   é”™è¯¯ [{Path(img_path).name}]: {e}")
            results.append({
                'image': ann['image'],
                'has_seg': False,
                'has_mask': False,
                'error': str(e),
            })
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\n" + "=" * 60)
    print("ğŸ“Š è¯„ä¼°ç»“æœ")
    print("=" * 60)
    
    total = len(results)
    seg_count = sum(1 for r in results if r.get('has_seg', False))
    mask_count = sum(1 for r in results if r.get('has_mask', False))
    
    print(f"æ€»æ ·æœ¬æ•°: {total}")
    print(f"ç”Ÿæˆ[SEG]: {seg_count}/{total} ({seg_count/total*100:.1f}%)")
    print(f"ç”ŸæˆMask: {mask_count}/{total} ({mask_count/total*100:.1f}%)")
    
    # IoUç»Ÿè®¡
    valid_ious = [r['pred_iou_with_chosen'] for r in results if r.get('pred_iou_with_chosen') is not None]
    if valid_ious:
        print(f"\nä¸Chosen Maskçš„IoU:")
        print(f"  å¹³å‡: {np.mean(valid_ious):.4f}")
        print(f"  æœ€å°: {np.min(valid_ious):.4f}")
        print(f"  æœ€å¤§: {np.max(valid_ious):.4f}")
    
    # ä¿å­˜ç»“æœ
    result_path = os.path.join(args.output_dir, 'eval_results.json')
    with open(result_path, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nç»“æœä¿å­˜: {result_path}")
    
    print("=" * 60)

if __name__ == '__main__':
    main()
