#!/usr/bin/env python3
"""
æµ‹è¯•DPOè®­ç»ƒåçš„æ¨¡å‹æ•ˆæœ
å¯¹æ¯”åŸå§‹æ¨¡å‹å’ŒDPOæ¨¡å‹çš„åˆ†å‰²è´¨é‡
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/ubuntu/Sa2VA')

def calculate_iou(pred_mask, gt_mask):
    """è®¡ç®—IoU"""
    pred = pred_mask > 0.5
    gt = gt_mask > 0.5
    intersection = np.logical_and(pred, gt).sum()
    union = np.logical_or(pred, gt).sum()
    if union == 0:
        return 1.0 if intersection == 0 else 0.0
    return intersection / union

def calculate_dice(pred_mask, gt_mask):
    """è®¡ç®—Diceç³»æ•°"""
    pred = pred_mask > 0.5
    gt = gt_mask > 0.5
    intersection = np.logical_and(pred, gt).sum()
    if pred.sum() + gt.sum() == 0:
        return 1.0 if intersection == 0 else 0.0
    return 2 * intersection / (pred.sum() + gt.sum())

def load_model(checkpoint_path, config_path):
    """åŠ è½½æ¨¡å‹"""
    from mmengine.config import Config
    from mmengine.registry import MODELS
    from mmengine.runner import load_checkpoint
    
    cfg = Config.fromfile(config_path)
    model = MODELS.build(cfg.model)
    
    if checkpoint_path:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        # è¿‡æ»¤å¹¶åŠ è½½æƒé‡
        model_state = model.state_dict()
        filtered = {}
        for k, v in state_dict.items():
            if k in model_state and v.shape == model_state[k].shape:
                filtered[k] = v
        model.load_state_dict(filtered, strict=False)
        print(f"Loaded {len(filtered)}/{len(state_dict)} weights from {checkpoint_path}")
    
    model.eval()
    model.cuda()
    return model

def test_single_image(model, image_path, prompt="Please segment the blood vessel in this image."):
    """æµ‹è¯•å•å¼ å›¾ç‰‡"""
    from transformers import AutoTokenizer
    from torchvision import transforms
    
    # åŠ è½½å›¾ç‰‡
    image = Image.open(image_path).convert('RGB')
    
    # ä½¿ç”¨æ¨¡å‹æ¨ç†
    with torch.no_grad():
        try:
            result = model.generate_mask(image, prompt)
            return result
        except Exception as e:
            print(f"æ¨ç†é”™è¯¯: {e}")
            return None

def evaluate_on_dataset(model, data_root, ann_file, num_samples=50):
    """åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°"""
    with open(ann_file, 'r') as f:
        annotations = json.load(f)
    
    # éšæœºé‡‡æ ·
    if len(annotations) > num_samples:
        import random
        random.seed(42)
        annotations = random.sample(annotations, num_samples)
    
    results = {
        'iou_scores': [],
        'dice_scores': [],
        'success_count': 0,
        'total_count': len(annotations)
    }
    
    for ann in tqdm(annotations, desc="è¯„ä¼°ä¸­"):
        image_path = os.path.join(data_root, 'images', ann['image'])
        if not os.path.exists(image_path):
            continue
        
        try:
            pred_mask = test_single_image(model, image_path)
            if pred_mask is not None:
                results['success_count'] += 1
                # å¦‚æœæœ‰GT maskï¼Œè®¡ç®—æŒ‡æ ‡
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªç»Ÿè®¡æˆåŠŸæ¨ç†çš„æ•°é‡
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
    
    return results

def quick_visual_test(checkpoint_path, test_images_dir, output_dir):
    """å¿«é€Ÿå¯è§†åŒ–æµ‹è¯•"""
    import matplotlib.pyplot as plt
    from transformers import AutoTokenizer, AutoModel
    
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æµ‹è¯•å›¾ç‰‡
    test_images = list(Path(test_images_dir).glob("*.jpg"))[:5]
    
    print(f"\nğŸ” æµ‹è¯• {len(test_images)} å¼ å›¾ç‰‡...")
    print(f"   æ¨¡å‹: {checkpoint_path}")
    
    for img_path in test_images:
        print(f"   - {img_path.name}")
    
    return test_images

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint', type=str, 
                       default='/home/ubuntu/Sa2VA/work_dirs/dpo_vessel_training/iter_1224.pth',
                       help='DPOæ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--baseline', type=str,
                       default='/home/ubuntu/Sa2VA/work_dirs/merged_vessel_segmentation/iter_3672.pth',
                       help='åŸºçº¿æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--test_dir', type=str,
                       default='/home/ubuntu/Sa2VA/data/dpo_vessel/images',
                       help='æµ‹è¯•å›¾ç‰‡ç›®å½•')
    parser.add_argument('--num_samples', type=int, default=10,
                       help='æµ‹è¯•æ ·æœ¬æ•°')
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ§ª DPOæ¨¡å‹æ•ˆæœæµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶
    print("\nğŸ“ æ£€æŸ¥æ–‡ä»¶...")
    print(f"   DPOæ¨¡å‹: {os.path.exists(args.checkpoint)} - {args.checkpoint}")
    print(f"   åŸºçº¿æ¨¡å‹: {os.path.exists(args.baseline)} - {args.baseline}")
    print(f"   æµ‹è¯•ç›®å½•: {os.path.exists(args.test_dir)} - {args.test_dir}")
    
    # ç»Ÿè®¡æµ‹è¯•å›¾ç‰‡
    test_images = list(Path(args.test_dir).glob("*.jpg"))
    print(f"   æµ‹è¯•å›¾ç‰‡æ•°: {len(test_images)}")
    
    # æ£€æŸ¥checkpointå†…å®¹
    print("\nğŸ“Š Checkpointä¿¡æ¯:")
    
    if os.path.exists(args.checkpoint):
        ckpt = torch.load(args.checkpoint, map_location='cpu', weights_only=False)
        if 'state_dict' in ckpt:
            print(f"   DPOæ¨¡å‹å‚æ•°æ•°: {len(ckpt['state_dict'])}")
            # æ˜¾ç¤ºä¸€äº›å…³é”®å‚æ•°
            lora_params = [k for k in ckpt['state_dict'].keys() if 'lora' in k.lower()]
            print(f"   LoRAå‚æ•°æ•°: {len(lora_params)}")
        if 'meta' in ckpt:
            print(f"   è®­ç»ƒè¿­ä»£: {ckpt['meta'].get('iter', 'N/A')}")
            print(f"   è®­ç»ƒepoch: {ckpt['meta'].get('epoch', 'N/A')}")
    
    if os.path.exists(args.baseline):
        ckpt = torch.load(args.baseline, map_location='cpu', weights_only=False)
        if 'state_dict' in ckpt:
            print(f"   åŸºçº¿æ¨¡å‹å‚æ•°æ•°: {len(ckpt['state_dict'])}")
    
    print("\nâœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ!")
    print("\nğŸ’¡ è¦è¿›è¡Œå®Œæ•´æ¨ç†æµ‹è¯•ï¼Œè¯·è¿è¡Œ:")
    print(f"   python scripts/inference_sa2va.py --checkpoint {args.checkpoint}")

if __name__ == '__main__':
    main()
