# Sa2VA 血管分割数据集说明

## 数据集概述

**数据集名称**: 血管造影分割数据集 (Vessel Angiography Segmentation Dataset)  
**数据集路径**: `/home/ubuntu/Sa2VA/data/vessel_data/`  
**数据集类型**: 医学影像 - 血管造影图像分割

---

## 数据集统计

### 基本信息
- **总样本数**: 1,219 张图像
- **实际图像文件**: 1,220 张 (有1张未标注)
- **来源视频数**: 36 个视频
- **平均每视频帧数**: 33.9 帧
- **图像格式**: JPG

### 数据分布
| 统计项 | 数值 |
|--------|------|
| 标注样本数 | 1,219 |
| 未标注图像 | 1 (`Fang Kun^(0000470101)_1-4_1_04A2C7DF_frame_000015.jpg`) |
| 最少帧数视频 | 20 帧 |
| 最多帧数视频 | 40 帧 |

---

## 数据格式

### 文件结构
```
vessel_data/
├── images/                          # 图像文件夹
│   ├── An Cong Xue(...)_frame_000011.jpg
│   ├── An Cong Xue(...)_frame_000012.jpg
│   └── ...
└── annotations.json                 # 标注文件
```

### Annotations格式

**文件**: `annotations.json`  
**格式**: JSON数组，每个元素包含：

```json
{
  "image": "An Cong Xue(0000932433)_1-3_1_051C3E6A_frame_000011.jpg",
  "mask": [
    [300, 73, 150, 71, 220, 115, 189, 91, 271, 93, 235, 71]
  ],
  "text": ["blood vessel"]
}
```

#### 字段说明

1. **`image`** (string)
   - 图像文件名
   - 格式: `{患者名}_{序列号}_frame_{帧号}.jpg`
   - 示例: `An Cong Xue(0000932433)_1-3_1_051C3E6A_frame_000011.jpg`

2. **`mask`** (list of lists)
   - 血管分割掩码的多边形坐标
   - 格式: `[[x1, y1, x2, y2, x3, y3, ...], ...]`
   - 每个子列表代表一个血管区域的多边形顶点坐标
   - 坐标系: 图像左上角为原点 (0, 0)
   - 一张图像可能包含多个血管区域（1-8个mask）

3. **`text`** (list of strings)
   - 文本标注/描述
   - 所有样本均为: `["blood vessel"]`
   - 用于视觉-语言模型的文本理解

---

## 输入输出定义

### 训练时的输入输出

#### 输入 (Input)
1. **图像** (Image)
   - 类型: RGB图像
   - 来源: 血管造影X光片
   - 内容: 显示血管结构的医学影像

2. **文本提示** (Text Prompt)
   - 类型: 字符串
   - 内容: "blood vessel" 或类似的血管分割指令
   - 作用: 指导模型进行特定任务

#### 输出 (Output)
1. **分割掩码** (Segmentation Mask)
   - 类型: 二值掩码或概率图
   - 内容: 血管区域的像素级分割
   - 格式: 与输入图像同尺寸

2. **文本响应** (Text Response)
   - 类型: 字符串
   - 内容: 对血管分割结果的描述
   - 示例: "已识别并分割出血管区域"

---

## Mask数量分布

| Mask数量 | 样本数 | 占比 |
|---------|--------|------|
| 1个 | 1,088 | 89.3% |
| 2个 | 72 | 5.9% |
| 3个 | 26 | 2.1% |
| 4个 | 16 | 1.3% |
| 5个 | 9 | 0.7% |
| 6个 | 4 | 0.3% |
| 7个 | 1 | 0.1% |
| 8个 | 3 | 0.2% |

**说明**: 大部分图像(89.3%)只包含1个血管区域，少数图像包含多个分支血管。

---

## 视频来源分析

数据集来自36个不同患者的血管造影视频，每个视频被采样为多帧图像：

### 示例视频统计
| 视频ID | 帧数 |
|--------|------|
| An Cong Xue(0000932433)_1-3_1_051C3E6A | 20 |
| Bai Hui Min(0000202318)_1-3_1_04DB6FD9 | 40 |
| Bai Hui Min(0000202318)_1-4_1_04DB6FDA | 40 |
| Ban Sheng Yuan(0000779783)_1-7_1_0491E522 | 20 |
| Chen Chao Mo(0000523667)_1-7_1_052104B7 | 20 |

**特点**:
- 同一视频的连续帧高度相似
- 血管位置和形状在短时间内变化很小
- 适合单帧分割任务，但存在数据冗余

---

## 数据集数量验证

### ✅ 数量对照检查

| 项目 | 预期数量 | 实际数量 | 状态 |
|------|---------|---------|------|
| Annotations条目 | - | 1,219 | ✅ |
| 图像文件 | 1,219 | 1,220 | ⚠️ 多1个 |
| 未标注图像 | 0 | 1 | ⚠️ |
| 视频数量 | - | 36 | ✅ |

### ⚠️ 数据不一致说明

**问题**: 图像目录中有1,220个文件，但annotations.json只有1,219条记录

**原因**: 有1张图像未被标注
- 文件名: `Fang Kun^(0000470101)_1-4_1_04A2C7DF_frame_000015.jpg`
- 可能原因: 图像质量问题或标注遗漏

**影响**: 
- ✅ 不影响训练（训练只使用有标注的1,219张）
- ⚠️ 该图像未被利用

---

## 训练配置中的数据使用

### 实际训练样本数计算

```python
原始样本数 = 1,219
数据重复次数 (repeats) = 10
训练轮数 (epochs) = 1

实际训练样本数 = 1,219 × 10 = 12,190
总迭代数 = 12,190 / (4 GPUs × 1 batch) = 3,047.5 ≈ 3,048
实际总迭代数 = 12,192 (考虑梯度累积)
```

### 数据增强策略
- **重复采样**: 每个样本重复10次
- **随机打乱**: 每个epoch重新打乱顺序
- **动态batch**: 根据图像大小动态调整

---

## 数据集特点

### 优势
1. ✅ **专业标注**: 医学专业人员标注的血管区域
2. ✅ **多样性**: 36个不同患者，覆盖不同血管结构
3. ✅ **高质量**: 清晰的血管造影图像
4. ✅ **多边形标注**: 精确的多边形顶点坐标

### 局限性
1. ⚠️ **样本量有限**: 仅1,219张图像
2. ⚠️ **数据冗余**: 连续视频帧高度相似
3. ⚠️ **单一任务**: 仅标注"blood vessel"，无细分类别
4. ⚠️ **时序未利用**: 视频帧被当作独立图像处理

---

## 数据集适用任务

### ✅ 适合的任务
- 血管分割 (Vessel Segmentation)
- 医学图像分割
- 视觉-语言多模态学习
- 单帧图像理解

### ❌ 不适合的任务
- 血管分类（无细分类别）
- 视频级时序分析（未利用时序信息）
- 3D血管重建（仅2D图像）
- 血管病变检测（无病变标注）

---

## 数据集引用

如果使用此数据集，请引用：
- **项目**: Sa2VA (Segment Anything 2 + Vision-Language Assistant)
- **论文**: Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding
- **链接**: https://github.com/magic-research/Sa2VA

---

## 数据集访问

**本地路径**: `/home/ubuntu/Sa2VA/data/vessel_data/`

**文件清单**:
```
vessel_data/
├── images/              (1,220 张图像)
└── annotations.json     (1,219 条标注)
```

**加载示例**:
```python
import json
with open('annotations.json', 'r') as f:
    annotations = json.load(f)

# 访问第一个样本
sample = annotations[0]
print(f"图像: {sample['image']}")
print(f"Mask数量: {len(sample['mask'])}")
print(f"文本: {sample['text']}")
```

---

**文档更新时间**: 2025-11-22  
**数据集版本**: v1.0
