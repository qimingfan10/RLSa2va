# ğŸ” HuggingFaceè½¬æ¢è¿‡ç¨‹é—®é¢˜åˆ†æ

## ğŸš¨ **é—®é¢˜å‘ç°**

é€šè¿‡æ·±å…¥æ£€æŸ¥ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸ºä»€ä¹ˆä¸¤ä¸ªä¸åŒçš„è®­ç»ƒcheckpointï¼ˆæƒé‡ç›¸å·®96%ï¼‰è½¬æ¢æˆHFæ¨¡å‹åæ¨ç†æ€§èƒ½å®Œå…¨ç›¸åŒã€‚

---

## ğŸ“Š **è¯æ®é“¾**

### 1ï¸âƒ£ åŸå§‹Checkpointç¡®å®ä¸åŒ

```bash
æ£€æŸ¥ç»“æœ:
â”œâ”€â”€ å…±åŒå‚æ•°: 536ä¸ª
â”œâ”€â”€ å®Œå…¨ç›¸åŒ: 20ä¸ª (3.73%)
â””â”€â”€ ä¸åŒå‚æ•°: 516ä¸ª (96.27%) âœ…

å…³é”®å‚æ•°å·®å¼‚:
- lm_head.weight: å¹³å‡å·®å¼‚ 1.84e-04, æœ€å¤§å·®å¼‚ 9.22e-03
- sam2_decoder:   å¹³å‡å·®å¼‚ 1.48e-03, æœ€å¤§å·®å¼‚ 1.15e-02
```

**ç»“è®º**: ä¸¤ä¸ªcheckpointæƒé‡æ˜æ˜¾ä¸åŒï¼

### 2ï¸âƒ£ HFæ¨¡å‹æƒé‡å´å®Œå…¨ç›¸åŒ

```bash
HFæ¨¡å‹ç¬¬ä¸€ä¸ªsafetensorsæ–‡ä»¶å¯¹æ¯”:
- embed_tokens.weight:        å·®å¼‚ 0.000000e+00 âŒ
- layers.0.input_layernorm:   å·®å¼‚ 0.000000e+00 âŒ  
- layers.0.mlp.down_proj:     å·®å¼‚ 0.000000e+00 âŒ
- layers.0.mlp.gate_proj:     å·®å¼‚ 0.000000e+00 âŒ
- layers.0.mlp.up_proj:       å·®å¼‚ 0.000000e+00 âŒ
```

**ç»“è®º**: è½¬æ¢åçš„HFæ¨¡å‹æƒé‡å®Œå…¨ç›¸åŒï¼

### 3ï¸âƒ£ é…ç½®æ–‡ä»¶ç›¸åŒ

```bash
config.jsonå¯¹æ¯”:
âœ… llm_config: ç›¸åŒ
âœ… vision_config: ç›¸åŒ
âœ… template: ç›¸åŒ
âœ… architectures: ç›¸åŒ
```

---

## ğŸ” **æ ¹æœ¬åŸå› åˆ†æ**

### è½¬æ¢è„šæœ¬æ‰§è¡Œæµç¨‹

æ–‡ä»¶ï¼š`tools/convert_to_hf.py`

```python
# æ­¥éª¤1: åŠ è½½é…ç½®
cfg = Config.fromfile(args.config)  # è¯»å–é…ç½®æ–‡ä»¶

# æ­¥éª¤2: æ„å»ºæ¨¡å‹ âš ï¸ å…³é”®ç‚¹
model = BUILDER.build(cfg.model)
# è¿™ä¼šè°ƒç”¨ Sa2VAModel.__init__()
# åœ¨__init__ä¸­ä¼šæ‰§è¡Œ:
#   if pretrained_pth is not None:
#       pretrained_state_dict = guess_load_checkpoint(pretrained_pth)
#       self.load_state_dict(filtered_state_dict, strict=False)
#       print(f'Load pretrained weight from {pretrained_pth}')

# æ­¥éª¤3: åŠ è½½è®­ç»ƒcheckpoint
state_dict = torch.load(args.pth_model, map_location='cpu')['state_dict']

# æ­¥éª¤4: å†æ¬¡load_state_dict âš ï¸ å…³é”®ç‚¹
model.load_state_dict(state_dict, strict=False)
print(f'Load PTH model from {args.pth_model}')
```

### é—®é¢˜æ‰€åœ¨

**æ­¥éª¤2çš„è¯¦ç»†è¿‡ç¨‹** (from `sa2va.py`):

```python
def __init__(self, ..., pretrained_pth=None):
    # ... åˆå§‹åŒ–å„ç§æ¨¡å— ...
    
    if pretrained_pth is not None:  # â† è¿™é‡Œï¼
        pretrained_state_dict = guess_load_checkpoint(pretrained_pth)
        model_state_dict = self.state_dict()
        filtered_state_dict = {}
        
        for k, v in pretrained_state_dict.items():
            if k in model_state_dict:
                if v.shape == model_state_dict[k].shape:
                    filtered_state_dict[k] = v  # â† åŠ è½½é¢„è®­ç»ƒæƒé‡
        
        self.load_state_dict(filtered_state_dict, strict=False)
        print(f'Load pretrained weight from {pretrained_pth}')
```

### é…ç½®æ–‡ä»¶å†…å®¹

**ä¸¤ä¸ªé…ç½®éƒ½æŒ‡å‘åŒä¸€ä¸ªé¢„è®­ç»ƒæƒé‡**:

```python
# sa2va_vessel_finetune.py (æ—§æ¨¡å‹é…ç½®)
pretrained_pth = "/home/ubuntu/Sa2VA-26B.pth"

# sa2va_merged_vessel_finetune.py (æ–°æ¨¡å‹é…ç½®)
pretrained_pth = "/home/ubuntu/Sa2VA-26B.pth"
```

---

## ğŸ¯ **é—®é¢˜æ€»ç»“**

### è½¬æ¢æµç¨‹

```
æ—§æ¨¡å‹è½¬æ¢ (iter_12192.pth):
â”œâ”€â”€ 1. è¯»å– sa2va_vessel_finetune.py
â”œâ”€â”€ 2. æ„å»ºæ¨¡å‹ â†’ åŠ è½½ Sa2VA-26B.pth âœ…
â”œâ”€â”€ 3. åŠ è½½ iter_12192.pth (strict=False)
â”‚      â””â”€â”€ åªæ›´æ–°è®­ç»ƒè¿‡çš„å‚æ•°
â””â”€â”€ 4. ä¿å­˜ä¸º HFæ ¼å¼

æ–°æ¨¡å‹è½¬æ¢ (iter_3672.pth):
â”œâ”€â”€ 1. è¯»å– sa2va_merged_vessel_finetune.py
â”œâ”€â”€ 2. æ„å»ºæ¨¡å‹ â†’ åŠ è½½ Sa2VA-26B.pth âœ… (åŒä¸€ä¸ªï¼)
â”œâ”€â”€ 3. åŠ è½½ iter_3672.pth (strict=False)
â”‚      â””â”€â”€ åªæ›´æ–°è®­ç»ƒè¿‡çš„å‚æ•°
â””â”€â”€ 4. ä¿å­˜ä¸º HFæ ¼å¼
```

### ä¸ºä»€ä¹ˆæƒé‡ç›¸åŒï¼Ÿ

**ä¸¤ä¸ªHFæ¨¡å‹çš„å¤§éƒ¨åˆ†æƒé‡æ¥è‡ªåŒä¸€ä¸ª`Sa2VA-26B.pth`ï¼**

1. **åŸºç¡€æƒé‡ç›¸åŒ**: ä¸¤æ¬¡è½¬æ¢éƒ½å…ˆåŠ è½½äº†`Sa2VA-26B.pth`
2. **è®­ç»ƒæƒé‡è¦†ç›–æœ‰é™**: `strict=False`åªæ›´æ–°è®­ç»ƒè¿‡çš„å‚æ•°
3. **å¦‚æœè®­ç»ƒä½¿ç”¨äº†LoRA**: å¤§éƒ¨åˆ†backboneå‚æ•°æ²¡æœ‰è¢«è®­ç»ƒæ›´æ–°
4. **ç»“æœ**: ä¸¤ä¸ªHFæ¨¡å‹çš„ä¸»è¦å‚æ•°ï¼ˆå¦‚embed_tokens, layer weightsï¼‰ä¿æŒç›¸åŒ

---

## ğŸ“ˆ **è½¬æ¢æ—¥å¿—éªŒè¯**

### æ—§æ¨¡å‹è½¬æ¢æ—¥å¿— (convert_to_hf.log)

```
11/22 14:09:00 - INFO - Loads checkpoint from: pretrained/sam2/sam2_hiera_large.pt
11/22 14:09:01 - INFO - Loaded checkpoint successfully

Load pretrained weight from /home/ubuntu/Sa2VA-26B.pth  â† å…ˆåŠ è½½è¿™ä¸ªï¼

Skipped 3 mismatched keys:
- text_hidden_fcs.0.weight: checkpoint shape [6144, 6144] vs model shape [3584, 3584]
- text_hidden_fcs.0.bias: checkpoint shape [6144] vs model shape [3584]
- text_hidden_fcs.2.weight: checkpoint shape [256, 6144] vs model shape [256, 3584]

Load PTH model from work_dirs/vessel_segmentation/iter_12192.pth  â† ç„¶ååŠ è½½è®­ç»ƒcheckpoint
```

**åˆ†æ**:
- æ˜ç¡®æ˜¾ç¤ºå…ˆåŠ è½½äº†`Sa2VA-26B.pth`
- ç„¶åæ‰åŠ è½½è®­ç»ƒcheckpoint
- è®­ç»ƒcheckpointåªæ›´æ–°äº†åŒ¹é…çš„å‚æ•°

---

## ğŸ¤” **ä¸ºä»€ä¹ˆCheckpointä¸åŒä½†HFç›¸åŒï¼Ÿ**

### å¯èƒ½çš„è§£é‡Š

#### 1ï¸âƒ£ **ä½¿ç”¨äº†LoRAè®­ç»ƒ** (æœ€å¯èƒ½)

å¦‚æœè®­ç»ƒä½¿ç”¨äº†LoRAé€‚é…å™¨:
- åªè®­ç»ƒLoRAå‚æ•°ï¼ˆå°æ¨¡å—ï¼‰
- backboneå‚æ•°å†»ç»“ä¸è®­ç»ƒ
- checkpointä¸­çš„å·®å¼‚å¯èƒ½ä¸»è¦åœ¨LoRAå‚æ•°
- ä½†è½¬æ¢HFæ—¶å¯èƒ½åˆå¹¶äº†LoRAæˆ–åªä¿å­˜äº†backbone

#### 2ï¸âƒ£ **ä¸åŒè®­ç»ƒé˜¶æ®µçš„åŒä¸€æ¨¡å‹**

- iter_12192 å’Œ iter_3672å¯èƒ½æ˜¯åŒä¸€ä¸ªè®­ç»ƒçš„ä¸åŒé˜¶æ®µ
- é…ç½®æ–‡ä»¶åä¸åŒä½†å®é™…è®­ç»ƒè¿‡ç¨‹ç›¸åŒ
- åªæ˜¯åœ¨ä¸åŒepochä¿å­˜çš„checkpoint

#### 3ï¸âƒ£ **è®­ç»ƒæƒé‡è¢«è¦†ç›–**

```python
# ä¼ªä»£ç è¯´æ˜é—®é¢˜
model.load_state_dict(Sa2VA_26B, strict=False)  # å…ˆåŠ è½½åŸºç¡€æƒé‡
model.load_state_dict(training_ckpt, strict=False)  # å†åŠ è½½è®­ç»ƒæƒé‡

# å¦‚æœ training_ckpt åªåŒ…å«å°‘é‡å‚æ•°æ›´æ–°
# å¤§éƒ¨åˆ†æƒé‡ä»ç„¶æ˜¯ Sa2VA_26B çš„å€¼
```

---

## âœ… **éªŒè¯æ–¹æ³•**

### å½“å‰æ­£åœ¨è¿›è¡Œ

**100å¼ å›¾ç‰‡å¤§è§„æ¨¡è¯„ä¼°**:
- ç›®çš„: ç¡®è®¤æ˜¯å¦æœ‰å¾®å°å·®å¼‚æœªè¢«10å¼ æ ·æœ¬æ£€æµ‹åˆ°
- é¢„è®¡æ—¶é—´: 20-30åˆ†é’Ÿ
- çŠ¶æ€: è¿›è¡Œä¸­...

### å»ºè®®çš„é¢å¤–éªŒè¯

1. **æ£€æŸ¥è®­ç»ƒæ˜¯å¦ä½¿ç”¨LoRA**
   ```bash
   grep -r "lora" /home/ubuntu/Sa2VA/projects/sa2va/configs/
   ```

2. **å¯¹æ¯”HFæ¨¡å‹çš„æ‰€æœ‰æƒé‡æ–‡ä»¶**
   ```python
   # åŠ è½½å¹¶å¯¹æ¯”æ‰€æœ‰7ä¸ªsafetensorsæ–‡ä»¶
   # æŸ¥çœ‹æ˜¯å¦æœ‰ä»»ä½•å‚æ•°ä¸åŒ
   ```

3. **æŸ¥çœ‹è®­ç»ƒé…ç½®ä¸­çš„å†»ç»“å‚æ•°**
   ```python
   # æ£€æŸ¥å“ªäº›å‚æ•°è¢«å†»ç»“
   # å“ªäº›å‚æ•°å®é™…è¢«è®­ç»ƒ
   ```

4. **ç›´æ¥ç”¨checkpointæ¨ç†**
   ```python
   # ç»•è¿‡HFè½¬æ¢
   # ç›´æ¥åŠ è½½checkpointè¿›è¡Œæ¨ç†
   # çœ‹æ˜¯å¦æœ‰å·®å¼‚
   ```

---

## ğŸ¯ **ç»“è®º**

### ç¡®è®¤çš„äº‹å®

1. âœ… **åŸå§‹checkpointç¡®å®ä¸åŒ** (96%å‚æ•°æœ‰å·®å¼‚)
2. âœ… **HFè½¬æ¢åçš„æ¨¡å‹æƒé‡ç›¸åŒ** (å‰5ä¸ªå‚æ•°å·®å¼‚ä¸º0)
3. âœ… **ä¸¤æ¬¡è½¬æ¢éƒ½åŠ è½½äº†åŒä¸€ä¸ªSa2VA-26B.pth**
4. âœ… **è½¬æ¢è¿‡ç¨‹ä½¿ç”¨strict=Falseå…è®¸éƒ¨åˆ†è¦†ç›–**

### æœ€å¯èƒ½çš„åŸå› 

**è½¬æ¢è¿‡ç¨‹æ²¡æœ‰æ­£ç¡®ä¿ç•™è®­ç»ƒcheckpointçš„å·®å¼‚**

- ç”±äºå…ˆåŠ è½½`Sa2VA-26B.pth`ï¼ŒååŠ è½½è®­ç»ƒcheckpoint
- ä¸”ä½¿ç”¨`strict=False`
- å¦‚æœè®­ç»ƒåªæ›´æ–°äº†éƒ¨åˆ†å‚æ•°ï¼ˆå¦‚LoRAï¼‰
- å¤§éƒ¨åˆ†å‚æ•°ä¿æŒäº†`Sa2VA-26B.pth`çš„å€¼
- å¯¼è‡´ä¸¤ä¸ªHFæ¨¡å‹å®è´¨ä¸Šæ˜¯ç›¸åŒçš„

### ç­‰å¾…100å¼ è¯„ä¼°ç»“æœ

å¦‚æœ100å¼ å›¾ç‰‡è¯„ä¼°ç»“æœä»ç„¶ç›¸åŒï¼Œåˆ™åŸºæœ¬ç¡®è®¤ï¼š
**ä¸¤ä¸ªHFæ¨¡å‹å®é™…ä¸Šæ˜¯ç›¸åŒçš„ï¼Œè½¬æ¢è¿‡ç¨‹å­˜åœ¨é—®é¢˜ã€‚**

---

## ğŸ› ï¸ **å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ**

### æ–¹æ¡ˆ1: ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡

ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œåœ¨è½¬æ¢æ—¶ä¸åŠ è½½`Sa2VA-26B.pth`:

```python
# ä¸´æ—¶é…ç½®ç”¨äºè½¬æ¢
pretrained_pth = None  # ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡
```

### æ–¹æ¡ˆ2: ä¿®æ”¹è½¬æ¢è„šæœ¬

```python
# åœ¨ convert_to_hf.py ä¸­
# åœ¨æ„å»ºæ¨¡å‹ä¹‹å‰ä¸´æ—¶ç§»é™¤ pretrained_pth
cfg.model.pretrained_pth = None
model = BUILDER.build(cfg.model)

# ç„¶ååŠ è½½å®Œæ•´çš„è®­ç»ƒcheckpoint
model.load_state_dict(state_dict, strict=False)
```

### æ–¹æ¡ˆ3: å¼ºåˆ¶åŠ è½½è®­ç»ƒcheckpoint

```python
# ä½¿ç”¨æ›´ä¸¥æ ¼çš„åŠ è½½ç­–ç•¥
model.load_state_dict(state_dict, strict=True)
# æˆ–è€…ç¡®ä¿è®­ç»ƒcheckpointå®Œå…¨è¦†ç›–æ¨¡å‹å‚æ•°
```

---

**æ›´æ–°æ—¶é—´**: 2025-11-25 19:00  
**çŠ¶æ€**: 100å¼ å›¾ç‰‡è¯„ä¼°è¿›è¡Œä¸­...  
**ä¸‹ä¸€æ­¥**: ç­‰å¾…è¯„ä¼°ç»“æœç¡®è®¤å‡è®¾
