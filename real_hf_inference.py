#!/usr/bin/env python3
"""
ä½¿ç”¨è½¬æ¢åçš„HuggingFaceæ ¼å¼æ¨¡å‹è¿›è¡ŒçœŸå®æ¨ç†
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import cv2
from pathlib import Path

print("=" * 80)
print("Sa2VAè¡€ç®¡åˆ†å‰² - çœŸå®HuggingFaceæ¨¡å‹æ¨ç†")
print("=" * 80)

# é…ç½®
model_path = '/home/ubuntu/Sa2VA/work_dirs/vessel_segmentation/iter_12192_hf'
data_root = '/home/ubuntu/Sa2VA/data/vessel_data/'
output_dir = '/home/ubuntu/Sa2VA/real_hf_inference_results/'

print(f"\næ¨¡å‹è·¯å¾„: {model_path}")
print(f"æ•°æ®è·¯å¾„: {data_root}")
print(f"è¾“å‡ºç›®å½•: {output_dir}")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(output_dir, exist_ok=True)
os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)

# æ£€æŸ¥GPU
print("\næ£€æŸ¥GPU...")
if not torch.cuda.is_available():
    print("âŒ CUDAä¸å¯ç”¨")
    sys.exit(1)

num_gpus = torch.cuda.device_count()
print(f"âœ… æ£€æµ‹åˆ° {num_gpus} ä¸ªGPU")
for i in range(num_gpus):
    print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    mem_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
    print(f"    æ€»æ˜¾å­˜: {mem_total:.2f} GB")

# åŠ è½½æ¨¡å‹
print("\nåŠ è½½HuggingFaceæ ¼å¼çš„æ¨¡å‹...")
print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")

try:
    from transformers import AutoModel, AutoTokenizer
    
    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨device_mapè‡ªåŠ¨å¤šGPUåˆ†é…ï¼‰
    print("  åŠ è½½æ¨¡å‹...")
    model = AutoModel.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        low_cpu_mem_usage=True,
        trust_remote_code=True,
        device_map="auto"  # è‡ªåŠ¨åˆ†é…åˆ°å¤šä¸ªGPU
    ).eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # åŠ è½½tokenizer
    print("  åŠ è½½tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")
    
    # æ˜¾ç¤ºæ˜¾å­˜ä½¿ç”¨
    print("\nå½“å‰æ˜¾å­˜ä½¿ç”¨:")
    for i in range(num_gpus):
        mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
        mem_reserved = torch.cuda.memory_reserved(i) / 1024**3
        print(f"  GPU {i}: å·²åˆ†é… {mem_allocated:.2f} GB, å·²ä¿ç•™ {mem_reserved:.2f} GB")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# åŠ è½½æ•°æ®
print("\nåŠ è½½æµ‹è¯•æ•°æ®...")
with open(os.path.join(data_root, 'annotations.json'), 'r') as f:
    annotations = json.load(f)

print(f"æ€»æ ·æœ¬æ•°: {len(annotations)}")

# é€‰æ‹©æµ‹è¯•æ ·æœ¬
test_samples = annotations[::10][:5]  # æµ‹è¯•5ä¸ªæ ·æœ¬
print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}")

# è¾…åŠ©å‡½æ•°
def polygon_to_mask(polygon_coords, image_shape):
    """å°†å¤šè¾¹å½¢åæ ‡è½¬æ¢ä¸ºæ©ç """
    mask = np.zeros(image_shape[:2], dtype=np.uint8)
    if len(polygon_coords) == 0:
        return mask
    
    points = []
    for i in range(0, len(polygon_coords), 2):
        if i + 1 < len(polygon_coords):
            points.append([polygon_coords[i], polygon_coords[i+1]])
    
    if len(points) > 0:
        points = np.array(points, dtype=np.int32)
        cv2.fillPoly(mask, [points], 1)
    
    return mask

def calculate_metrics(pred_mask, gt_mask, threshold=0.5):
    """è®¡ç®—åˆ†å‰²è¯„ä»·æŒ‡æ ‡"""
    pred_binary = (pred_mask > threshold).astype(np.uint8)
    gt_binary = (gt_mask > threshold).astype(np.uint8)
    
    TP = np.sum((pred_binary == 1) & (gt_binary == 1))
    FP = np.sum((pred_binary == 1) & (gt_binary == 0))
    FN = np.sum((pred_binary == 0) & (gt_binary == 1))
    TN = np.sum((pred_binary == 0) & (gt_binary == 0))
    
    dice = (2 * TP) / (2 * TP + FP + FN + 1e-8)
    iou = TP / (TP + FP + FN + 1e-8)
    precision = TP / (TP + FP + 1e-8)
    recall = TP / (TP + FN + 1e-8)
    specificity = TN / (TN + FP + 1e-8)
    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)
    
    return {
        'dice': dice,
        'iou': iou,
        'precision': precision,
        'recall': recall,
        'specificity': specificity,
        'accuracy': accuracy
    }

# å¼€å§‹çœŸå®æ¨ç†
print("\nå¼€å§‹çœŸå®HuggingFaceæ¨¡å‹æ¨ç†...")
print("-" * 80)

all_metrics = {
    'dice': [],
    'iou': [],
    'precision': [],
    'recall': [],
    'specificity': [],
    'accuracy': []
}

results = []

for idx, sample in enumerate(tqdm(test_samples, desc="çœŸå®æ¨ç†è¿›åº¦")):
    try:
        # åŠ è½½å›¾åƒ
        img_path = os.path.join(data_root, 'images', sample['image'])
        image = Image.open(img_path).convert('RGB')
        image_np = np.array(image)
        
        # åˆ›å»ºground truth mask
        gt_mask = polygon_to_mask(sample['mask'][0] if sample['mask'] else [], image_np.shape)
        
        print(f"\næ ·æœ¬ {idx+1}: {sample['image']}")
        print("  æ‰§è¡ŒçœŸå®æ¨¡å‹æ¨ç†...")
        
        with torch.no_grad():
            # ä½¿ç”¨HuggingFaceæ¨¡å‹çš„predict_forwardæ–¹æ³•
            try:
                result = model.predict_forward(
                    image=image,
                    text="blood vessel",
                    tokenizer=tokenizer
                )
                
                print("  âœ… çœŸå®æ¨ç†æˆåŠŸï¼")
                
                # æå–é¢„æµ‹æ©ç 
                if 'prediction_masks' in result and result['prediction_masks'] is not None and len(result['prediction_masks']) > 0:
                    pred_mask = result['prediction_masks'][0]
                    
                    # è½¬æ¢ä¸ºnumpy
                    if torch.is_tensor(pred_mask):
                        pred_mask = pred_mask.cpu().numpy()
                    
                    # è°ƒæ•´å½¢çŠ¶
                    if pred_mask.ndim == 3:
                        pred_mask = pred_mask[0]
                    
                    # ç¡®ä¿ä¸GTç›¸åŒå°ºå¯¸
                    if pred_mask.shape != gt_mask.shape:
                        pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]))
                    
                    # å½’ä¸€åŒ–åˆ°[0, 1]
                    if pred_mask.max() > 1:
                        pred_mask = pred_mask / 255.0
                    
                    print(f"  é¢„æµ‹æ©ç å½¢çŠ¶: {pred_mask.shape}")
                    print(f"  é¢„æµ‹å€¼èŒƒå›´: [{pred_mask.min():.3f}, {pred_mask.max():.3f}]")
                    print(f"  è¿™æ˜¯çœŸå®çš„æ¨¡å‹é¢„æµ‹ï¼")
                    
                else:
                    print("  âš ï¸  æ¨¡å‹æœªè¿”å›é¢„æµ‹æ©ç ")
                    # åˆ›å»ºç©ºæ©ç 
                    pred_mask = np.zeros_like(gt_mask, dtype=float)
                    
            except Exception as e:
                print(f"  âŒ æ¨ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # åˆ›å»ºç©ºæ©ç 
                pred_mask = np.zeros_like(gt_mask, dtype=float)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(pred_mask, gt_mask)
        
        print(f"  Dice: {metrics['dice']:.4f}, IoU: {metrics['iou']:.4f}")
        
        # è®°å½•æŒ‡æ ‡
        for key in all_metrics:
            all_metrics[key].append(metrics[key])
        
        # ä¿å­˜ç»“æœ
        results.append({
            'image': sample['image'],
            'metrics': metrics,
            'prediction_text': result.get('prediction', '') if 'result' in locals() else ''
        })
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        
        axes[0].imshow(image_np)
        axes[0].set_title('Original Image')
        axes[0].axis('off')
        
        axes[1].imshow(gt_mask, cmap='gray')
        axes[1].set_title('Ground Truth')
        axes[1].axis('off')
        
        axes[2].imshow(pred_mask, cmap='gray')
        axes[2].set_title(f'Real Model Prediction\n(HuggingFace)')
        axes[2].axis('off')
        
        axes[3].imshow(image_np)
        axes[3].imshow(pred_mask, alpha=0.5, cmap='Greens')
        axes[3].imshow(gt_mask, alpha=0.3, cmap='Reds')
        axes[3].set_title(f'Overlay\nDice: {metrics["dice"]:.4f}, IoU: {metrics["iou"]:.4f}')
        axes[3].axis('off')
        
        plt.tight_layout()
        vis_path = os.path.join(output_dir, 'visualizations', f'real_hf_pred_{idx:03d}.png')
        plt.savefig(vis_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… å¯è§†åŒ–å·²ä¿å­˜: {vis_path}")
        
        # æ˜¾ç¤ºå½“å‰æ˜¾å­˜ä½¿ç”¨
        print(f"  å½“å‰æ˜¾å­˜ä½¿ç”¨:")
        for i in range(num_gpus):
            mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
            print(f"    GPU {i}: {mem_allocated:.2f} GB")
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        continue

# æ±‡æ€»ç»“æœ
print("\n" + "=" * 80)
print("çœŸå®HuggingFaceæ¨¡å‹æ¨ç†ç»“æœæ±‡æ€»")
print("=" * 80)

for key in all_metrics:
    if len(all_metrics[key]) > 0:
        mean_val = np.mean(all_metrics[key])
        std_val = np.std(all_metrics[key])
        print(f"{key.upper():15s}: {mean_val:.4f} Â± {std_val:.4f}")

# ä¿å­˜ç»“æœ
results_json = {
    'model_type': 'HuggingFace (Real Inference)',
    'model_path': model_path,
    'num_gpus': num_gpus,
    'summary': {key: {'mean': float(np.mean(vals)), 'std': float(np.std(vals))} 
                for key, vals in all_metrics.items() if len(vals) > 0},
    'details': results
}

with open(os.path.join(output_dir, 'real_hf_inference_results.json'), 'w') as f:
    json.dump(results_json, f, indent=2)

print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {os.path.join(output_dir, 'real_hf_inference_results.json')}")
print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {os.path.join(output_dir, 'visualizations/')}")

# æœ€ç»ˆæ˜¾å­˜ä½¿ç”¨
print("\næœ€ç»ˆæ˜¾å­˜ä½¿ç”¨:")
for i in range(num_gpus):
    mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
    mem_reserved = torch.cuda.memory_reserved(i) / 1024**3
    print(f"  GPU {i}: å·²åˆ†é… {mem_allocated:.2f} GB, å·²ä¿ç•™ {mem_reserved:.2f} GB")

print("\n" + "=" * 80)
print("ğŸ‰ çœŸå®HuggingFaceæ¨¡å‹æ¨ç†å®Œæˆï¼")
print("=" * 80)
