# ğŸš€ LoRA + PPOå¿«é€Ÿå¯åŠ¨æŒ‡å—

**åˆ›å»ºæ—¶é—´**: 2025-11-29 15:13  
**çŠ¶æ€**: âœ… ä»£ç å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ

---

## ğŸ“‹ å·²å®Œæˆçš„å·¥ä½œ

### âœ… æ ¸å¿ƒä»£ç å®ç°
1. **`reward_functions.py`** - å¤šç›®æ ‡å¥–åŠ±å‡½æ•° â­â­â­â­â­
   - MultiObjectiveReward: Dice + Recall + æ‹“æ‰‘ + é•¿åº¦
   - SimpleDiceReward: ä»…Dice
   - RecallFocusedReward: ä¸“æ³¨Recall

2. **`lora_config.py`** - LoRAé…ç½®
   - é¢„è®¾é…ç½® (small/medium/large)
   - è‡ªåŠ¨è®¡ç®—å¯è®­ç»ƒå‚æ•°
   - ä¿å­˜/åŠ è½½/åˆå¹¶åŠŸèƒ½

3. **`data_loader.py`** - æ•°æ®åŠ è½½
   - è‡ªåŠ¨æ•°æ®åˆ’åˆ† (train/val/test)
   - æ”¯æŒæ•°æ®å¢å¼º
   - é«˜æ•ˆDataLoader

4. **`train_lora_ppo.py`** - ä¸»è®­ç»ƒè„šæœ¬
   - Sa2VA + LoRAé›†æˆ
   - ç®€åŒ–ç‰ˆPPOè®­ç»ƒå¾ªç¯
   - å®Œæ•´çš„éªŒè¯å’Œä¿å­˜é€»è¾‘

5. **`run_lora_ppo.sh`** - è¿è¡Œè„šæœ¬
   - Quickæ¨¡å¼ (50å¼ , 1 epoch, ~30åˆ†é’Ÿ)
   - Fullæ¨¡å¼ (1000å¼ , 3 epochs, ~24-48å°æ—¶)

6. **`install_dependencies.sh`** - ä¾èµ–å®‰è£…
7. **`README.md`** - å®Œæ•´æ–‡æ¡£

---

## ğŸ¯ ç«‹å³å¼€å§‹

### ç¬¬1æ­¥ï¼šå®‰è£…ä¾èµ– (5åˆ†é’Ÿ)

```bash
cd /home/ubuntu/Sa2VA/lora_ppo_training
bash install_dependencies.sh
```

**å®‰è£…å†…å®¹**:
- PEFT (LoRAå®ç°)
- scikit-image (æ‹“æ‰‘åˆ†æ)
- OpenCV (å›¾åƒå¤„ç†)
- wandb (å¯é€‰ï¼Œå®éªŒè¿½è¸ª)
- accelerate (è®­ç»ƒåŠ é€Ÿ)

### ç¬¬2æ­¥ï¼šå¿«é€Ÿæµ‹è¯• (30åˆ†é’Ÿ)

```bash
bash run_lora_ppo.sh quick
```

**é…ç½®**:
```yaml
è®­ç»ƒæ ·æœ¬: 50å¼ 
éªŒè¯æ ·æœ¬: 20å¼ 
è®­ç»ƒè½®æ•°: 1 epoch
LoRA Rank: 32
å­¦ä¹ ç‡: 5e-5
GPU: GPU1
```

**ç›®çš„**:
- âœ… éªŒè¯ä»£ç æ­£å¸¸è¿è¡Œ
- âœ… æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³
- âœ… ç¡®è®¤æ— bugå’Œé”™è¯¯
- âš ï¸ æ€§èƒ½æå‡æœ‰é™ï¼ˆæ ·æœ¬å¤ªå°‘ï¼‰

### ç¬¬3æ­¥ï¼šæŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹æ—¥å¿—
tail -100 output/train_quick_*.log

# æŸ¥çœ‹è®­ç»ƒä¿¡æ¯
cat output/sa2va_lora_ppo_*/training_info.json

# æ£€æŸ¥æœ€ä½³æ¨¡å‹
ls -lh output/sa2va_lora_ppo_*/best_lora/
```

### ç¬¬4æ­¥ï¼šå®Œæ•´è®­ç»ƒ (24-48å°æ—¶)

```bash
bash run_lora_ppo.sh full
```

**é…ç½®**:
```yaml
è®­ç»ƒæ ·æœ¬: 1000å¼ 
éªŒè¯æ ·æœ¬: 100å¼ 
è®­ç»ƒè½®æ•°: 3 epochs
é¢„æœŸDice: 0.85-0.87+
é¢„æœŸRecall: 0.83-0.85+
```

---

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### å®æ—¶ç›‘æ§

```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f output/train_full_*.log

# æŸ¥çœ‹GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train_lora_ppo
```

### å…³é”®æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­å…³æ³¨ï¼š
- âœ… **train/dice**: åº”è¯¥é€æ¸ä¸Šå‡
- âœ… **train/recall**: ç›®æ ‡0.85+
- âœ… **val/dice**: æœ€é‡è¦çš„æŒ‡æ ‡
- âš ï¸ **loss/reward**: åº”è¯¥ç¨³å®šæˆ–ä¸Šå‡

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### Quickæ¨¡å¼
```
è¿è¡ŒæˆåŠŸ: æ— é”™è¯¯ï¼Œæ­£å¸¸å®Œæˆ
GPUå†…å­˜: ä¸è¶…è¿‡80GB
è®­ç»ƒé€Ÿåº¦: æ¯ä¸ªepoch ~30åˆ†é’Ÿ
```

### Fullæ¨¡å¼
```
Dice: â‰¥ 0.87
Recall: â‰¥ 0.85
Precision: â‰¥ 0.85
è®­ç»ƒç¨³å®š: æ— NaNæˆ–å´©æºƒ
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: ä¾èµ–å®‰è£…å¤±è´¥

```bash
# ä½¿ç”¨æ¸…åé•œåƒæº
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple peft scikit-image opencv-python
```

### é—®é¢˜2: GPUå†…å­˜ä¸è¶³

```bash
# ä¿®æ”¹run_lora_ppo.sh
LORA_RANK=16  # é™ä½rankï¼ˆä»32é™åˆ°16ï¼‰
```

### é—®é¢˜3: è®­ç»ƒå¤ªæ…¢

```bash
# å‡å°‘éªŒè¯é¢‘ç‡
VAL_FREQ=200  # ä»100å¢åŠ åˆ°200
```

### é—®é¢˜4: Sa2VAåŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -lh /home/ubuntu/Sa2VA/models/sa2va_vessel_hf/

# ç¡®è®¤tokenizeræ­£å¸¸
python3 -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('/home/ubuntu/Sa2VA/models/sa2va_vessel_hf', trust_remote_code=True)"
```

---

## ğŸ“ˆ é¢„æœŸæ—¶é—´çº¿

### Quickæ¨¡å¼
```
0:00  â–¶ å¯åŠ¨è„šæœ¬
0:05  â³ å®‰è£…ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
0:10  â³ åŠ è½½Sa2VAæ¨¡å‹
0:15  â³ åº”ç”¨LoRA
0:20  â³ åŠ è½½æ•°æ®
0:25  ğŸ”„ å¼€å§‹è®­ç»ƒ
0:55  âœ… è®­ç»ƒå®Œæˆ
```

### Fullæ¨¡å¼
```
0:00   â–¶ å¯åŠ¨è„šæœ¬
0:15   â³ åˆå§‹åŒ–
0:30   ğŸ”„ Epoch 1/3
8:00   â³ Epoch 1 å®Œæˆ
16:00  â³ Epoch 2 å®Œæˆ
24:00  â³ Epoch 3 å®Œæˆ
24:30  âœ… è®­ç»ƒå®Œæˆ
```

---

## ğŸ“ å…³é”®æŠ€æœ¯ç‚¹

### 1. å¥–åŠ±å‡½æ•°è®¾è®¡ (æœ€é‡è¦)

**å½“å‰è®¾è®¡**:
```python
reward = 0.5 * dice_reward +      # ä¸»è¦ä¼˜åŒ–ç›®æ ‡
         0.2 * recall_bonus +     # é’ˆå¯¹Recallä½çš„é—®é¢˜
         0.2 * topology_reward +  # ä¿è¯è¡€ç®¡è¿ç»­æ€§
         0.1 * length_penalty     # çº¦æŸæ€»é•¿åº¦
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**:
- Diceç›´æ¥ä¼˜åŒ–åˆ†å‰²è´¨é‡
- Recall bonusä¸“é—¨æå‡æ•æ„Ÿåº¦
- æ‹“æ‰‘å¥–åŠ±å‡å°‘è¡€ç®¡æ–­è£‚
- é•¿åº¦çº¦æŸé˜²æ­¢è¿‡åº¦é¢„æµ‹

### 2. LoRAåŸç†

**æ ¸å¿ƒæ€æƒ³**: ä¸ä¿®æ”¹é¢„è®­ç»ƒæƒé‡ï¼Œåªæ·»åŠ ä½ç§©çŸ©é˜µ
```
W = W_frozen + Î”W
Î”W = A Ã— B  # A: (d, r), B: (r, d), r << d
```

**ä¼˜åŠ¿**:
- å‚æ•°å°‘ (0.5% vs 100%)
- è®­ç»ƒå¿«
- æ˜“äºåˆ‡æ¢å’Œåˆå¹¶
- ä¿æŒé¢„è®­ç»ƒçŸ¥è¯†

### 3. RLä¼˜åŒ–Dice

**ä¸ºä»€ä¹ˆRLèƒ½åšåˆ°è€Œç›‘ç£å­¦ä¹ åšä¸åˆ°**:
```python
# ç›‘ç£å­¦ä¹ 
loss = CrossEntropy(pred, gt)  # åƒç´ çº§å‡†ç¡®ç‡
# é—®é¢˜ï¼šä¼˜åŒ–çš„ä¸æ˜¯Dice

# å¼ºåŒ–å­¦ä¹ 
reward = Dice(pred, gt)  # ç›´æ¥ä¼˜åŒ–Diceï¼
loss = -reward
```

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### å¦‚æœDiceä¸è¾¾æ ‡

1. **è°ƒæ•´å¥–åŠ±æƒé‡**
```bash
# ä¸“æ³¨Dice
--dice_weight 0.7 --recall_weight 0.1

# ä¸“æ³¨Recall
--dice_weight 0.3 --recall_weight 0.5
```

2. **å¢åŠ è®­ç»ƒæ•°æ®**
```bash
MAX_TRAIN_SAMPLES=2000  # ä½¿ç”¨æ›´å¤šæ•°æ®
```

3. **æé«˜LoRA rank**
```bash
LORA_RANK=64  # æ›´å¤šå‚æ•°
LORA_ALPHA=128
```

4. **Curriculum Learning**
```python
# ä¿®æ”¹data_loader.py
# å…ˆè®­ç»ƒç®€å•æ ·æœ¬ï¼ˆå¤§è¡€ç®¡ï¼‰
# å†è®­ç»ƒå›°éš¾æ ·æœ¬ï¼ˆç»†å°è¡€ç®¡ï¼‰
```

### å¦‚æœRecallæå‡ä½†Precisionä¸‹é™

```bash
# æ·»åŠ Precisionçº¦æŸ
# ä¿®æ”¹reward_functions.py
if precision < 0.85:
    precision_penalty = (0.85 - precision) * 10.0
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ä»¥ä¸‹æ–‡ä»¶ï¼š

```
output/
â””â”€â”€ sa2va_lora_ppo_20251129_xxxxxx/
    â”œâ”€â”€ best_lora/                    # æœ€ä½³æ¨¡å‹ï¼ˆéªŒè¯é›†ï¼‰
    â”‚   â”œâ”€â”€ adapter_config.json
    â”‚   â””â”€â”€ adapter_model.safetensors
    â”œâ”€â”€ final_lora/                   # æœ€ç»ˆæ¨¡å‹
    â”œâ”€â”€ checkpoint_epoch_1/           # Epoch 1 checkpoint
    â”œâ”€â”€ checkpoint_epoch_2/           # Epoch 2 checkpoint
    â”œâ”€â”€ checkpoint_epoch_3/           # Epoch 3 checkpoint
    â””â”€â”€ training_info.json            # è®­ç»ƒä¿¡æ¯
```

**ä½¿ç”¨æœ€ä½³æ¨¡å‹**:
```bash
# è¯„ä¼°
python evaluate_lora.py \
    --base_model /path/to/sa2va \
    --lora_weights output/sa2va_lora_ppo_*/best_lora

# æ¨ç†
python inference_with_lora.py \
    --base_model /path/to/sa2va \
    --lora_weights output/sa2va_lora_ppo_*/best_lora \
    --image /path/to/test_image.jpg
```

---

## ğŸ‰ æœŸå¾…ç»“æœ

### Quickæ¨¡å¼ï¼ˆéªŒè¯å¯è¡Œæ€§ï¼‰
```
è¿è¡Œæ—¶é—´: âœ… ~30åˆ†é’Ÿ
ä»£ç æ­£å¸¸: âœ… æ— é”™è¯¯
GPUå†…å­˜: âœ… ä¸OOM
Diceæå‡: âš ï¸ æœ‰é™ï¼ˆæ ·æœ¬å°‘ï¼‰
```

### Fullæ¨¡å¼ï¼ˆè¾¾æˆç›®æ ‡ï¼‰
```
Dice:      0.78 â†’ 0.87+ âœ… (+11.5%)
Recall:    0.74 â†’ 0.85+ âœ… (+14.9%)
Precision: 0.84 â†’ 0.85+ âœ… (+1.2%)
æ‹“æ‰‘:      æ˜¾è‘—æ”¹å–„ âœ…
```

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³æ‰§è¡Œï¼ˆä»Šå¤©ï¼‰

```bash
# 1. è¿›å…¥ç›®å½•
cd /home/ubuntu/Sa2VA/lora_ppo_training

# 2. å®‰è£…ä¾èµ–
bash install_dependencies.sh

# 3. å¿«é€Ÿæµ‹è¯•
bash run_lora_ppo.sh quick

# 4. æ£€æŸ¥ç»“æœï¼ˆ30åˆ†é’Ÿåï¼‰
tail -100 output/train_quick_*.log
```

### éªŒè¯é€šè¿‡åï¼ˆæ˜å¤©ï¼‰

```bash
# å¯åŠ¨å®Œæ•´è®­ç»ƒ
bash run_lora_ppo.sh full

# åå°è¿è¡Œï¼ˆæ¨èï¼‰
nohup bash run_lora_ppo.sh full > lora_ppo_full.log 2>&1 &

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train_lora_ppo
```

### è®­ç»ƒå®Œæˆåï¼ˆ2-3å¤©åï¼‰

```bash
# 1. è¯„ä¼°æ€§èƒ½
python evaluate_lora_model.py

# 2. å¯¹æ¯”æ‰€æœ‰å®éªŒ
python compare_all_experiments.py

# 3. æ’°å†™æœ€ç»ˆæŠ¥å‘Š
# 4. é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆéƒ¨ç½²
```

---

## âœ… æ£€æŸ¥æ¸…å•

è®­ç»ƒå‰ç¡®è®¤ï¼š
- [ ] ä¾èµ–å·²å®‰è£… (`bash install_dependencies.sh`)
- [ ] GPUå¯ç”¨ (`nvidia-smi`)
- [ ] æ•°æ®é›†å­˜åœ¨ (`ls /home/ubuntu/Sa2VA/data/merged_vessel_data`)
- [ ] æ¨¡å‹å­˜åœ¨ (`ls /home/ubuntu/Sa2VA/models/sa2va_vessel_hf`)
- [ ] ç£ç›˜ç©ºé—´å……è¶³ (`df -h`)

è®­ç»ƒä¸­ç›‘æ§ï¼š
- [ ] è¿›ç¨‹æ­£å¸¸è¿è¡Œ (`ps aux | grep train`)
- [ ] GPUä½¿ç”¨ç‡åˆç† (`nvidia-smi`)
- [ ] æ—¥å¿—æ— é”™è¯¯ (`tail -f output/train_*.log`)
- [ ] Diceé€æ¸ä¸Šå‡

è®­ç»ƒåæ£€æŸ¥ï¼š
- [ ] æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (`ls output/sa2va_lora_ppo_*/best_lora`)
- [ ] è®­ç»ƒä¿¡æ¯å®Œæ•´ (`cat output/sa2va_lora_ppo_*/training_info.json`)
- [ ] éªŒè¯Diceè¾¾æ ‡ (â‰¥ 0.87)
- [ ] Recallè¾¾æ ‡ (â‰¥ 0.85)

---

**çŠ¶æ€**: âœ… å‡†å¤‡å°±ç»ª  
**å»ºè®®**: ç«‹å³è¿è¡ŒQuickæ¨¡å¼éªŒè¯  
**é¢„æœŸ**: Fullæ¨¡å¼è¾¾åˆ°Dice 0.87+, Recall 0.85+

**å¼€å§‹å‘½ä»¤**: `bash run_lora_ppo.sh quick` ğŸš€
