# Sa2VA DPO Training æŠ€æœ¯æ–‡æ¡£

## ä¸€ã€æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†å¯¹ Sa2VA-26B æ¨¡å‹è¿›è¡Œ DPO (Direct Preference Optimization) è®­ç»ƒçš„æ–¹æ³•è®ºã€å®éªŒè¿‡ç¨‹å’Œç»“è®ºã€‚

### 1.1 ç›®æ ‡

é€šè¿‡ DPO è®­ç»ƒæå‡ Sa2VA æ¨¡å‹åœ¨è¡€ç®¡åˆ†å‰²ï¼ˆVessel Segmentationï¼‰ä»»åŠ¡ä¸Šçš„ Dice ç³»æ•°ã€‚

### 1.2 åŸºçº¿æ€§èƒ½

| æŒ‡æ ‡ | Baseline å€¼ |
|------|-------------|
| Mean Dice | 0.8191 |
| Mean IoU | 0.6966 |
| Precision | 0.8743 |
| Recall | 0.7763 |

---

## äºŒã€æ–‡ä»¶ç»“æ„

### 2.1 æ¨¡å‹æ–‡ä»¶

```
/home/ubuntu/Sa2VA/models/sa2va_vessel_hf/    # Baselineæ¨¡å‹ï¼ˆHuggingFaceæ ¼å¼ï¼‰
â”œâ”€â”€ config.json
â”œâ”€â”€ modeling_sa2va_chat.py                     # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ sam2.py                                    # SAM2 åˆ†å‰²æ¨¡å—
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ pytorch_model-*.bin                        # æ¨¡å‹æƒé‡
â””â”€â”€ ...
```

### 2.2 è®­ç»ƒè„šæœ¬

| è„šæœ¬ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| **V8 Full Forward** | `/home/ubuntu/Sa2VA/scripts/train_dpo_v8_full_forward.py` | **æœ€ç»ˆç‰ˆæœ¬** - ä½¿ç”¨å®Œæ•´LLM forwardè·¯å¾„ |
| V7 Hybrid | `/home/ubuntu/Sa2VA/scripts/train_dpo_v7_hybrid.py` | æ··åˆDPO+DiceæŸå¤±ï¼ˆç®€åŒ–embeddingï¼‰ |
| V6 Hybrid | `/home/ubuntu/Sa2VA/scripts/train_dpo_v6_hybrid.py` | æ··åˆDPO+DiceæŸå¤± |

### 2.3 è¯„ä¼°è„šæœ¬

| è„šæœ¬ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| **ä¸»è¯„ä¼°è„šæœ¬** | `/home/ubuntu/Sa2VA/evaluate_10_images.py` | è¯„ä¼°10å¼ å›¾ç‰‡çš„åˆ†å‰²æ€§èƒ½ |

### 2.4 æ•°æ®æ–‡ä»¶

```
/home/ubuntu/Sa2VA/data/dpo_vessel/
â”œâ”€â”€ dpo_annotations.json          # DPOæ ‡æ³¨æ–‡ä»¶
â”œâ”€â”€ images/                       # åŸå§‹å›¾åƒ
â”œâ”€â”€ chosen_masks/                 # Chosen masks (Ground Truth)
â””â”€â”€ rejected_masks/               # Rejected masks (Baselineé¢„æµ‹)
```

**dpo_annotations.json æ ¼å¼ï¼š**
```json
[
  {
    "image": "images/xxx.png",
    "chosen_mask": "chosen_masks/xxx.png",
    "rejected_mask": "rejected_masks/xxx.png"
  },
  ...
]
```

---

## ä¸‰ã€æ–¹æ³•è®º

### 3.1 DPO åŸç†

DPO é€šè¿‡æœ€å¤§åŒ–ä»¥ä¸‹ç›®æ ‡å‡½æ•°æ¥å­¦ä¹ åå¥½ï¼š

$$L_{DPO} = -\log \sigma \left( \beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)} \right)$$

å…¶ä¸­ï¼š
- $y_w$: Chosen (åå¥½) æ ·æœ¬
- $y_l$: Rejected (æ‹’ç») æ ·æœ¬
- $\beta$: KL æ•£åº¦æƒ©ç½šç³»æ•°
- $\pi_\theta$: å½“å‰ç­–ç•¥
- $\pi_{ref}$: å‚è€ƒç­–ç•¥

### 3.2 åˆ†å‰²ä»»åŠ¡çš„ DPO é€‚é…

åœ¨åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†æ¦‚ç‡å®šä¹‰ä¸ºåŸºäº Dice ç›¸ä¼¼åº¦ï¼š

```python
log_prob_chosen = log(Dice(pred_mask, gt_mask) + Îµ)
log_prob_rejected = log(Dice(pred_mask, rejected_mask) + Îµ)
```

### 3.3 æ··åˆæŸå¤±å‡½æ•°

ä¸ºé˜²æ­¢ Dice ä¸‹é™ï¼Œé‡‡ç”¨æ··åˆæŸå¤±ï¼š

$$L_{total} = L_{DPO} + \lambda \cdot L_{Dice}$$

å…¶ä¸­ $\lambda = 1.0$ï¼ˆDiceæŸå¤±æƒé‡ï¼‰

### 3.4 æ•°æ®ç­›é€‰ç­–ç•¥

**ä¸¥æ ¼ç­›é€‰æ ‡å‡†ï¼š**
1. **Chosen = Ground Truth**ï¼šä¸ä½¿ç”¨æ¨¡å‹é¢„æµ‹ä½œä¸ºchosen
2. **Dice Gap â‰¥ 0.15**ï¼šç¡®ä¿chosenå’Œrejectedæœ‰è¶³å¤Ÿå·®å¼‚

```python
dice_gap = 1.0 - Dice(rejected_mask, gt_mask)
if dice_gap >= 0.15:
    # ä½¿ç”¨è¯¥æ ·æœ¬
```

### 3.5 æ¨¡å‹å†»ç»“ç­–ç•¥

| ç»„ä»¶ | çŠ¶æ€ | åŸå›  |
|------|------|------|
| Vision Encoder | â„ï¸ å†»ç»“ | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| LLM (LoRA) | ğŸ”¥ è®­ç»ƒ | å­¦ä¹ åå¥½ |
| text_hidden_fcs | ğŸ”¥ è®­ç»ƒ | è¿æ¥LLMå’ŒSAM2 |
| SAM2 Mask Decoder | ğŸ”¥ è®­ç»ƒ | ä¼˜åŒ–åˆ†å‰²è´¨é‡ |

---

## å››ã€è®­ç»ƒæµç¨‹

### 4.1 ç¯å¢ƒå‡†å¤‡

```bash
# æ¿€æ´»ç¯å¢ƒ
eval "$(/home/ubuntu/micromamba/micromamba/bin/micromamba shell hook --shell bash)"
micromamba activate topo-sarl
```

### 4.2 å…³é”®ä»£ç ä¿®æ”¹

**ç§»é™¤ sam2.py ä¸­çš„ `@torch.no_grad` è£…é¥°å™¨ï¼š**

```bash
# ä½ç½®ï¼š/home/ubuntu/Sa2VA/models/sa2va_vessel_hf/sam2.py
# è¡Œå·ï¼š1691, 1699, 1708, 3905, 3977

# å°†ä»¥ä¸‹è£…é¥°å™¨æ³¨é‡Šæ‰ï¼š
# @torch.no_grad()        -> # REMOVED for training
# @torch.inference_mode() -> # REMOVED for training
```

**åœ¨è¯„ä¼°è„šæœ¬ä¸­æ·»åŠ  `with torch.no_grad()`ï¼š**

```python
# /home/ubuntu/Sa2VA/evaluate_10_images.py
with torch.no_grad():
    result = model.predict_forward(
        image=image,
        text=text,
        tokenizer=tokenizer,
        processor=None,
    )
```

### 4.3 è¿è¡Œè®­ç»ƒ

```bash
cd /home/ubuntu/Sa2VA

# è¿è¡Œ V8 è®­ç»ƒï¼ˆæ¨èï¼‰
CUDA_VISIBLE_DEVICES=0,1,2,3 python scripts/train_dpo_v8_full_forward.py

# è¾“å‡ºç›®å½•
# /home/ubuntu/Sa2VA/work_dirs/sa2va_26b_dpo_v8/final/
```

### 4.4 è¶…å‚æ•°é…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| learning_rate | 1e-5 | ä¸­ç­‰å­¦ä¹ ç‡ |
| beta | 0.2 | DPO KLæƒ©ç½šç³»æ•° |
| dice_weight | 1.0 | DiceæŸå¤±æƒé‡ |
| lora_r | 16 | LoRAç§© |
| grad_accum | 4 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| max_samples | 500 | æœ€å¤§è®­ç»ƒæ ·æœ¬æ•° |

---

## äº”ã€è¯„ä¼°æµç¨‹

### 5.1 è¿è¡Œè¯„ä¼°

```bash
cd /home/ubuntu/Sa2VA

# è¯„ä¼° Baseline
python evaluate_10_images.py

# è¯„ä¼°è®­ç»ƒåçš„æ¨¡å‹
# ä¿®æ”¹ HF_MODEL_PATH ä¸ºè®­ç»ƒè¾“å‡ºè·¯å¾„
# HF_MODEL_PATH = "/home/ubuntu/Sa2VA/work_dirs/sa2va_26b_dpo_v8/final"
python evaluate_10_images.py
```

### 5.2 è¯„ä¼°æŒ‡æ ‡

- **Dice Score**: åˆ†å‰²é‡å åº¦ (2TP / (2TP + FP + FN))
- **IoU (Jaccard)**: äº¤å¹¶æ¯” (TP / (TP + FP + FN))
- **Precision**: ç²¾ç¡®ç‡ (TP / (TP + FP))
- **Recall**: å¬å›ç‡ (TP / (TP + FN))

---

## å…­ã€å®éªŒç»“æœ

### 6.1 ä¸åŒç‰ˆæœ¬å¯¹æ¯”

| ç‰ˆæœ¬ | æ–¹æ³• | å­¦ä¹ ç‡ | Mean Dice | ç»“è®º |
|------|------|--------|-----------|------|
| Baseline | - | - | **0.8191** | åŸºå‡† |
| V6 | ç®€åŒ–embedding + Hybrid Loss | 1e-6 | 0.8191 | æ— å˜åŒ–ï¼ˆæ¢¯åº¦è¢«é˜»æ–­ï¼‰ |
| V7 | ç§»é™¤è£…é¥°å™¨ + Hybrid Loss | 1e-6 | 0.8190 | æ— å˜åŒ– |
| V8 | å®Œæ•´LLM Forward | 1e-6 | 0.8193 | å¾®å°å˜åŒ– |
| V8b | å®Œæ•´LLM Forward | 5e-5 | 0.7978 | â†“ è¿‡æ‹Ÿåˆ |
| V8c | å®Œæ•´LLM Forward | 1e-5 | 0.8188 | åŸºæœ¬æŒå¹³ |

### 6.2 å…³é”®å‘ç°

1. **æ¢¯åº¦é˜»æ–­é—®é¢˜**ï¼š`@torch.no_grad` è£…é¥°å™¨å¿…é¡»ç§»é™¤æ‰èƒ½è¿›è¡Œè®­ç»ƒ
2. **è®­ç»ƒ-æ¨ç†è·¯å¾„ä¸ä¸€è‡´**ï¼šè®­ç»ƒç”¨ `forward()`ï¼Œæ¨ç†ç”¨ `generate()`
3. **å­¦ä¹ ç‡æ•æ„Ÿæ€§**ï¼šå¤ªå¤§å¯¼è‡´é—å¿˜ï¼Œå¤ªå°æ— æ•ˆæœ
4. **Baselineå·²ç»å¾ˆå¼º**ï¼šDice 0.82 éš¾ä»¥é€šè¿‡DPOæ˜¾è‘—æå‡

---

## ä¸ƒã€æ ¸å¿ƒä»£ç è§£æ

### 7.1 å®Œæ•´LLM Forwardè·å–[SEG] Embedding

```python
def _forward_get_seg_embedding(self, pixel_values, input_ids):
    """ä½¿ç”¨å®Œæ•´LLM forwardè·å–[SEG] embedding"""
    
    # 1. è·å–vision embeddings
    vit_embeds = self.model.extract_feature(pixel_values)
    
    # 2. è·å–text embeddings
    text_embeds = self.model.language_model.get_input_embeddings()(input_ids)
    
    # 3. æ›¿æ¢IMG_CONTEXTä½ç½®ä¸ºvision embeddings
    input_embeds = text_embeds.clone()
    img_context_mask = (input_ids == self.img_context_token_id)
    if img_context_mask.sum() > 0:
        vit_flat = vit_embeds.reshape(-1, C)
        img_positions = img_context_mask[0].nonzero(as_tuple=True)[0]
        input_embeds[0, img_positions] = vit_flat[:len(img_positions)]
    
    # 4. LLM forwardè·å–hidden states
    outputs = self.model.language_model(
        inputs_embeds=input_embeds,
        attention_mask=attention_mask,
        output_hidden_states=True,
    )
    
    # 5. æå–[SEG]ä½ç½®çš„hidden state
    hidden_states = outputs.hidden_states[-1]
    seg_mask = (input_ids == self.seg_token_id)
    seg_hidden = hidden_states[seg_mask]
    
    # 6. é€šè¿‡text_hidden_fcs
    seg_embedding = self.model.text_hidden_fcs(seg_hidden)
    
    return seg_embedding
```

### 7.2 DPO + Dice æ··åˆæŸå¤±

```python
def train_step(self, sample):
    # é¢„æµ‹mask
    pred_prob = torch.sigmoid(pred_logits)
    
    # DiceæŸå¤±
    loss_dice = dice_loss(pred_prob, gt_mask)
    
    # DPOæŸå¤±
    dice_with_gt = compute_dice(pred_prob, gt_mask)
    dice_with_rejected = compute_dice(pred_prob, rejected_mask)
    
    log_prob_chosen = torch.log(dice_with_gt + 1e-8)
    log_prob_rejected = torch.log(dice_with_rejected + 1e-8)
    loss_dpo = -F.logsigmoid(beta * (log_prob_chosen - log_prob_rejected))
    
    # æ··åˆæŸå¤±
    total_loss = loss_dpo + dice_weight * loss_dice
    
    return total_loss
```

---

## å…«ã€å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆDiceæ²¡æœ‰æ˜¾è‘—æå‡ï¼Ÿ

**A:** ä¸»è¦åŸå› ï¼š
1. Baselineå·²ç»å¾ˆå¼ºï¼ˆ0.82ï¼‰ï¼Œæ¥è¿‘ä»»åŠ¡ä¸Šé™
2. è®­ç»ƒ(`forward`)å’Œæ¨ç†(`generate`)è·¯å¾„ä¸ä¸€è‡´
3. DPOæ›´é€‚åˆåå¥½å­¦ä¹ ï¼Œä¸æ˜¯ç²¾ç¡®åƒç´ çº§ä»»åŠ¡

### Q2: å¦‚ä½•ç¡®ä¿æ¢¯åº¦æµåŠ¨ï¼Ÿ

**A:** 
1. ç§»é™¤ `sam2.py` ä¸­çš„ `@torch.no_grad` è£…é¥°å™¨
2. åœ¨è¯„ä¼°æ—¶ä½¿ç”¨ `with torch.no_grad():` ä¸Šä¸‹æ–‡ç®¡ç†å™¨
3. ç¡®ä¿ SAM2 Mask Decoder çš„ `requires_grad=True`

### Q3: æ¨èçš„ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘ï¼Ÿ

**A:**
1. ä½¿ç”¨ XTuner åŸç”Ÿè®­ç»ƒæ¡†æ¶ï¼ˆç»Ÿä¸€è®­ç»ƒæ¨ç†è·¯å¾„ï¼‰
2. å¢åŠ é«˜è´¨é‡DPOæ•°æ®
3. è€ƒè™‘ç›´æ¥ç›‘ç£å­¦ä¹ æ›¿ä»£DPO

---

## ä¹ã€é™„å½•

### 9.1 å®Œæ•´æ–‡ä»¶æ¸…å•

```
è®­ç»ƒç›¸å…³:
â”œâ”€â”€ /home/ubuntu/Sa2VA/scripts/train_dpo_v8_full_forward.py  # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ /home/ubuntu/Sa2VA/models/sa2va_vessel_hf/               # åŸºç¡€æ¨¡å‹
â”œâ”€â”€ /home/ubuntu/Sa2VA/data/dpo_vessel/                      # DPOæ•°æ®
â””â”€â”€ /home/ubuntu/Sa2VA/work_dirs/sa2va_26b_dpo_v8/          # è¾“å‡ºç›®å½•

è¯„ä¼°ç›¸å…³:
â”œâ”€â”€ /home/ubuntu/Sa2VA/evaluate_10_images.py                 # è¯„ä¼°è„šæœ¬
â””â”€â”€ /home/ubuntu/Sa2VA/data/dpo_vessel/                      # æµ‹è¯•æ•°æ®

æ–‡æ¡£:
â””â”€â”€ /home/ubuntu/Sa2VA/docs/DPO_Training_Documentation.md    # æœ¬æ–‡æ¡£
```

### 9.2 å‚è€ƒæ–‡çŒ®

1. DPO: Direct Preference Optimization (Rafailov et al., 2023)
2. SAM2: Segment Anything Model 2 (Meta AI, 2024)
3. Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ä½œè€…**: AI Assistant
