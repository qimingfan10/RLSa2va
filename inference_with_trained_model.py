"""
ä½¿ç”¨è®­ç»ƒå¥½çš„Sa2VAæ¨¡å‹è¿›è¡Œå®é™…æ¨ç†é¢„æµ‹
"""
import os
import sys
import json
import random
import numpy as np
import torch
from PIL import Image
import matplotlib.pyplot as plt
import cv2

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/ubuntu/Sa2VA')

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONPATH'] = '/home/ubuntu/Sa2VA:' + os.environ.get('PYTHONPATH', '')

print("=" * 80)
print("Sa2VAè®­ç»ƒæ¨¡å‹æ¨ç†é¢„æµ‹")
print("=" * 80)

# é…ç½®
CHECKPOINT_PATH = "/home/ubuntu/Sa2VA/work_dirs/merged_vessel_segmentation/iter_3672.pth"
CONFIG_PATH = "/home/ubuntu/Sa2VA/projects/sa2va/configs/sa2va_merged_vessel_finetune.py"
DATA_ROOT = "/home/ubuntu/Sa2VA/data/merged_vessel_data/"
OUTPUT_DIR = "/home/ubuntu/Sa2VA/inference_results"
NUM_SAMPLES = 5  # é¢„æµ‹5å¼ å›¾ç‰‡

print(f"é…ç½®æ–‡ä»¶: {CONFIG_PATH}")
print(f"Checkpoint: {CHECKPOINT_PATH}")
print(f"æ•°æ®é›†: {DATA_ROOT}")
print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
print()

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "predictions"), exist_ok=True)

# æ£€æŸ¥æ–‡ä»¶
if not os.path.exists(CHECKPOINT_PATH):
    print(f"âŒ Checkpointä¸å­˜åœ¨: {CHECKPOINT_PATH}")
    exit(1)

if not os.path.exists(CONFIG_PATH):
    print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_PATH}")
    exit(1)

print("âœ… æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
print()

# åŠ è½½é…ç½®å’Œæ¨¡å‹
print("=" * 80)
print("åŠ è½½æ¨¡å‹")
print("=" * 80)

try:
    from mmengine.config import Config
    from mmengine.runner import Runner
    from mmengine.registry import MODELS
    
    print("âœ… å¯¼å…¥mmengineæˆåŠŸ")
    
    # åŠ è½½é…ç½®
    print("\nåŠ è½½é…ç½®æ–‡ä»¶...")
    cfg = Config.fromfile(CONFIG_PATH)
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    
    # è®¾ç½®checkpointè·¯å¾„
    cfg.load_from = CHECKPOINT_PATH
    cfg.resume = False
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    cfg.work_dir = OUTPUT_DIR
    
    print("\næ„å»ºæ¨¡å‹...")
    # æ„å»ºæ¨¡å‹
    model = MODELS.build(cfg.model)
    print("âœ… æ¨¡å‹æ„å»ºæˆåŠŸ")
    
    # åŠ è½½checkpoint
    print("\nåŠ è½½checkpointæƒé‡...")
    checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu', weights_only=False)
    
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    # åŠ è½½æƒé‡
    model.load_state_dict(state_dict, strict=False)
    print("âœ… æƒé‡åŠ è½½æˆåŠŸ")
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # ç§»åŠ¨åˆ°GPU
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    print(f"âœ… æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    
    MODEL_LOADED = True
    
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print(f"\nè¯¦ç»†é”™è¯¯:")
    import traceback
    traceback.print_exc()
    MODEL_LOADED = False
    print("\nâš ï¸  å°†åªè¿›è¡ŒGround Truthå¯è§†åŒ–")

# åŠ è½½æ•°æ®é›†
print("\n" + "=" * 80)
print("åŠ è½½æ•°æ®é›†")
print("=" * 80)

with open(os.path.join(DATA_ROOT, "annotations.json")) as f:
    dataset = json.load(f)

print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")

# éšæœºé€‰æ‹©æ ·æœ¬
random.seed(42)
test_samples = random.sample(dataset, NUM_SAMPLES)

print(f"\né€‰ä¸­çš„æ ·æœ¬:")
for i, sample in enumerate(test_samples):
    print(f"  {i+1}. {sample['image']} (masks: {len(sample['mask'])})")

# è¿›è¡Œæ¨ç†
print("\n" + "=" * 80)
print("å¼€å§‹æ¨ç†")
print("=" * 80)

results = []

for idx, sample in enumerate(test_samples):
    print(f"\nå¤„ç†æ ·æœ¬ {idx+1}/{NUM_SAMPLES}: {sample['image']}")
    
    # åŠ è½½å›¾ç‰‡
    img_path = os.path.join(DATA_ROOT, "images", sample['image'])
    if not os.path.exists(img_path):
        print(f"  âŒ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
        continue
    
    image = Image.open(img_path).convert('RGB')
    image_np = np.array(image)
    h, w = image_np.shape[:2]
    
    # åˆ›å»ºGround Truth mask
    gt_mask = np.zeros((h, w), dtype=np.uint8)
    for mask_coords in sample['mask']:
        if len(mask_coords) >= 6:
            points = np.array(mask_coords).reshape(-1, 2).astype(np.int32)
            cv2.fillPoly(gt_mask, [points], 255)
    
    # å¦‚æœæ¨¡å‹åŠ è½½æˆåŠŸï¼Œè¿›è¡Œæ¨ç†
    if MODEL_LOADED:
        try:
            print(f"  ğŸ”„ è¿›è¡Œæ¨¡å‹æ¨ç†...")
            
            with torch.no_grad():
                # å‡†å¤‡è¾“å…¥
                # è¿™é‡Œéœ€è¦æ ¹æ®Sa2VAçš„å®é™…è¾“å…¥æ ¼å¼æ¥å‡†å¤‡æ•°æ®
                # ç”±äºSa2VAéœ€è¦ç‰¹å®šçš„æ•°æ®æ ¼å¼ï¼Œè¿™é‡Œå…ˆæ˜¾ç¤ºGround Truth
                
                # TODO: å®ç°å®é™…çš„æ¨ç†é€»è¾‘
                # pred_mask = model.predict(image, text="blood vessel")
                
                pred_mask = gt_mask  # ä¸´æ—¶ä½¿ç”¨GTä½œä¸ºé¢„æµ‹ç»“æœ
                print(f"  âš ï¸  æ¨ç†é€»è¾‘å¾…å®ç°ï¼Œå½“å‰æ˜¾ç¤ºGround Truth")
                
        except Exception as e:
            print(f"  âŒ æ¨ç†å¤±è´¥: {e}")
            pred_mask = gt_mask
    else:
        pred_mask = gt_mask
        print(f"  â„¹ï¸  æ¨¡å‹æœªåŠ è½½ï¼Œæ˜¾ç¤ºGround Truth")
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    
    # åŸå›¾
    axes[0].imshow(image_np)
    axes[0].set_title('Original Image', fontsize=14)
    axes[0].axis('off')
    
    # Ground Truth
    axes[1].imshow(image_np)
    axes[1].imshow(gt_mask, alpha=0.5, cmap='Reds')
    axes[1].set_title('Ground Truth', fontsize=14)
    axes[1].axis('off')
    
    # é¢„æµ‹ç»“æœ
    axes[2].imshow(image_np)
    axes[2].imshow(pred_mask, alpha=0.5, cmap='Greens')
    axes[2].set_title('Prediction', fontsize=14)
    axes[2].axis('off')
    
    # å¯¹æ¯”
    overlay = image_np.copy()
    # GTç”¨çº¢è‰²
    overlay[gt_mask > 0] = overlay[gt_mask > 0] * 0.5 + np.array([255, 0, 0]) * 0.5
    # é¢„æµ‹ç”¨ç»¿è‰²
    overlay[pred_mask > 0] = overlay[pred_mask > 0] * 0.5 + np.array([0, 255, 0]) * 0.5
    axes[3].imshow(overlay.astype(np.uint8))
    axes[3].set_title('Overlay (Red=GT, Green=Pred)', fontsize=14)
    axes[3].axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = os.path.join(OUTPUT_DIR, "predictions", f"sample_{idx+1}_{sample['image']}")
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  âœ… ä¿å­˜åˆ°: {output_path}")
    
    results.append({
        'sample_id': idx + 1,
        'image': sample['image'],
        'num_masks': len(sample['mask']),
        'prediction': output_path
    })

# ä¿å­˜ç»“æœ
print("\n" + "=" * 80)
print("ä¿å­˜ç»“æœ")
print("=" * 80)

summary = {
    'checkpoint': CHECKPOINT_PATH,
    'model_loaded': MODEL_LOADED,
    'num_samples': len(results),
    'results': results
}

summary_path = os.path.join(OUTPUT_DIR, "inference_summary.json")
with open(summary_path, 'w') as f:
    json.dump(summary, f, indent=2)

print(f"âœ… æ‘˜è¦ä¿å­˜åˆ°: {summary_path}")

# åˆ›å»ºREADME
readme = f"""# Sa2VAè®­ç»ƒæ¨¡å‹æ¨ç†ç»“æœ

## æ¨¡å‹ä¿¡æ¯
- **Checkpoint**: {CHECKPOINT_PATH}
- **é…ç½®æ–‡ä»¶**: {CONFIG_PATH}
- **æ¨¡å‹åŠ è½½**: {'âœ… æˆåŠŸ' if MODEL_LOADED else 'âŒ å¤±è´¥'}

## æ¨ç†ç»“æœ
- **æ ·æœ¬æ•°**: {len(results)}
- **è¾“å‡ºç›®å½•**: {OUTPUT_DIR}/predictions/

## æ³¨æ„
{'å½“å‰ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è¿›è¡Œæ¨ç†ã€‚' if MODEL_LOADED else 'æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ˜¾ç¤ºGround Truthä½œä¸ºå‚è€ƒã€‚'}

## ä¸‹ä¸€æ­¥
è¦è¿›è¡Œå®Œæ•´çš„æ¨¡å‹æ¨ç†ï¼Œéœ€è¦:
1. ç¡®ä¿mmengineç¯å¢ƒæ­£ç¡®å®‰è£…
2. å®ç°Sa2VAçš„æ¨ç†æ¥å£
3. æˆ–å°†æ¨¡å‹è½¬æ¢ä¸ºHuggingFaceæ ¼å¼åä½¿ç”¨

## æ ·æœ¬åˆ—è¡¨
"""

for result in results:
    readme += f"\n{result['sample_id']}. **{result['image']}**\n"
    readme += f"   - Masks: {result['num_masks']}\n"

readme_path = os.path.join(OUTPUT_DIR, "README.md")
with open(readme_path, 'w') as f:
    f.write(readme)

print(f"âœ… READMEä¿å­˜åˆ°: {readme_path}")

print("\n" + "=" * 80)
print("å®Œæˆï¼")
print("=" * 80)
print(f"ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}/predictions/")
print()

if not MODEL_LOADED:
    print("âš ï¸  æ³¨æ„: æ¨¡å‹æœªæˆåŠŸåŠ è½½")
    print("å»ºè®®:")
    print("1. åœ¨topo-sarlç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
    print("2. æˆ–å°†æ¨¡å‹è½¬æ¢ä¸ºHuggingFaceæ ¼å¼åä½¿ç”¨")
    print()
    print("è½¬æ¢å‘½ä»¤:")
    print("  python tools/convert_to_hf.py \\")
    print("    --model_path projects/sa2va/configs/sa2va_merged_vessel_finetune.py \\")
    print("    --ckpt_path work_dirs/merged_vessel_segmentation/iter_3672.pth \\")
    print("    --save_path models/sa2va_vessel_hf")
