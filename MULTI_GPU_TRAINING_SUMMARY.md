# 多GPU训练总结

## 🎯 您的需求

> "现在有4*24G的显卡啊，把显存压力分散开来"

## 📊 当前状况

### ✅ 成功的部分

1. **数据准备完成**:
   - 1220张图片，坐标已正确缩放
   - 600个样本从800×800缩放到512×512
   - 620个样本保持512×512

2. **模型可以分散到4个GPU**:
   ```
   GPU 0: 3.32 GB / 23.68 GB (14.0%)
   GPU 1: 4.34 GB / 23.68 GB (18.3%)
   GPU 2: 4.34 GB / 23.68 GB (18.3%)
   GPU 3: 3.24 GB / 23.68 GB (13.7%)
   总计: ~15 GB / 95 GB (16%)
   ```
   
3. **单GPU推理工作正常**:
   - 使用CUDA:0可以成功推理
   - Dice ~0.51, 预测形状连续平滑

### ❌ 遇到的问题

#### 问题1: mmengine训练时OOM

**错误**:
```
torch.OutOfMemoryError: CUDA out of memory. 
Tried to allocate 2.03 GiB. 
GPU 0 has a total capacity of 23.68 GiB of which 1.82 GiB is free.
```

**发生在**: `resize_token_embeddings()` - 模型初始化时
**原因**: 添加特殊token时需要临时分配大量显存，即使使用DeepSpeed Zero-3也无法避免

#### 问题2: 多GPU推理时设备不匹配

**错误**:
```
RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cuda:3)
```

**发生在**: `predict_forward()` - 多GPU推理时
**原因**: 模型分散在多个GPU上，但某些tensor操作期望在同一设备上

## 💡 解决方案对比

### 方案1: 单GPU推理 ✅ 可行

**优势**:
- 已验证可行
- 代码简单
- 无设备不匹配问题

**劣势**:
- 只使用1个GPU
- 推理速度较慢

**适用场景**: 评估当前模型性能

### 方案2: 数据并行推理 ⭐ 推荐

**思路**: 
- 不是模型并行（model parallelism）
- 而是数据并行（data parallelism）
- 每个GPU加载完整模型
- 不同GPU处理不同的数据

**实现**:
```python
# 每个GPU独立加载模型
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,
    device_map=f"cuda:{gpu_id}",  # 单个GPU
    trust_remote_code=True
)

# 使用torch.multiprocessing分配数据
```

**优势**:
- 充分利用4个GPU
- 无设备不匹配问题
- 推理速度提升4倍

**劣势**:
- 每个GPU需要加载完整模型（~15GB）
- 4×15GB = 60GB < 96GB ✅ 可行！

### 方案3: 修复多GPU模型并行 ⚠️ 复杂

**需要**:
- 修改Sa2VA的`predict_forward`代码
- 确保所有tensor在正确的设备上
- 处理跨设备的操作

**难度**: 高，需要深入理解模型代码

## 🎯 推荐方案：数据并行推理

### 实现步骤

1. **创建多进程推理脚本**
2. **每个进程**:
   - 使用一个GPU
   - 加载完整模型到该GPU
   - 处理1/4的数据
3. **汇总结果**

### 显存计算

```
单个模型: ~15 GB
4个GPU: 4 × 15 GB = 60 GB
总显存: 4 × 24 GB = 96 GB
剩余: 36 GB (用于batch处理和中间结果)
✅ 完全可行！
```

## 📝 具体建议

### 立即可行：在整个数据集上评估

**使用单GPU**:
```bash
# 使用已有的模型
# 在1220张图片上进行推理
# 计算平均性能指标
```

**预期时间**: 
- 每张图片 ~2.5秒
- 1220张 × 2.5秒 ≈ 50分钟

**优势**:
- 简单可靠
- 立即可以执行
- 获得完整的评估结果

### 中期方案：实现数据并行推理

**创建4进程推理脚本**:
- 进程0: GPU 0, 样本 0-304
- 进程1: GPU 1, 样本 305-609
- 进程2: GPU 2, 样本 610-914
- 进程3: GPU 3, 样本 915-1219

**预期时间**: 
- 50分钟 / 4 ≈ 12.5分钟

### 长期方案：重新训练（如果需要）

**如果当前模型性能不够**:
1. 使用HuggingFace格式模型
2. 实现自定义训练循环
3. 使用梯度累积和混合精度
4. 或者寻找其他训练框架

## 🔍 技术细节

### 为什么单GPU可以但多GPU不行？

**单GPU**:
```python
device_map="cuda:0"  # 所有层在GPU 0
# 所有tensor在同一设备 ✅
```

**多GPU模型并行**:
```python
device_map="balanced"  # 层分散在多个GPU
# vision_model在GPU 0
# language_model.layers[0-10]在GPU 1
# language_model.layers[11-20]在GPU 2
# 某些操作需要跨设备 ❌
```

### 为什么数据并行可行？

**数据并行**:
```python
# GPU 0: 完整模型 + 数据batch 1
# GPU 1: 完整模型 + 数据batch 2
# GPU 2: 完整模型 + 数据batch 3
# GPU 3: 完整模型 + 数据batch 4
# 每个GPU独立工作，无跨设备操作 ✅
```

## 📊 性能对比

| 方案 | GPU使用 | 推理时间 | 显存需求 | 实现难度 |
|------|---------|----------|----------|----------|
| 单GPU推理 | 1/4 | 50分钟 | 15GB | 简单 ✅ |
| 数据并行 | 4/4 | 12.5分钟 | 60GB | 中等 |
| 模型并行 | 4/4 | ? | 15GB | 困难 |

## 💬 结论

### 当前最佳方案

**立即执行**: 使用单GPU在整个数据集（1220张）上评估
- ✅ 已验证可行
- ✅ 代码已准备好
- ✅ 可以立即开始

**后续优化**: 如果需要更快的推理速度
- 实现数据并行推理
- 4个GPU同时工作
- 速度提升4倍

### 关于训练

**当前模型**:
- 已训练12k步
- Dice ~0.51
- 在220张图片上训练

**建议**:
1. 先在1220张图片上评估当前模型
2. 看性能是否满足需求
3. 如果不够，再考虑重新训练

**重新训练的挑战**:
- mmengine框架的OOM问题
- 需要修改模型初始化代码
- 或使用其他训练框架

---

**总结**: 4×24GB GPU的显存是充足的，关键是选择合适的并行策略。数据并行比模型并行更适合当前场景。
