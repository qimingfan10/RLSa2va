#!/usr/bin/env python3
"""
ä½¿ç”¨Segment_DATA_Merged_512æ•°æ®é›†è¿›è¡Œé¢„æµ‹
éšæœºé€‰æ‹©10å¼ å›¾ç‰‡
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import cv2
import random
from pathlib import Path

print("=" * 80)
print("Sa2VAè¡€ç®¡åˆ†å‰² - Segment_DATA_Merged_512æ•°æ®é›†é¢„æµ‹")
print("=" * 80)

# é…ç½®
model_path = '/home/ubuntu/Sa2VA/work_dirs/vessel_segmentation/iter_12192_hf'
data_root = '/home/ubuntu/Sa2VA/Segment_DATA_Merged_512/'
output_dir = '/home/ubuntu/Sa2VA/merged_dataset_predictions/'

print(f"\næ¨¡å‹è·¯å¾„: {model_path}")
print(f"æ•°æ®è·¯å¾„: {data_root}")
print(f"è¾“å‡ºç›®å½•: {output_dir}")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(output_dir, exist_ok=True)
os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)

# æ£€æŸ¥GPU
print("\næ£€æŸ¥GPU...")
if not torch.cuda.is_available():
    print("âŒ CUDAä¸å¯ç”¨")
    sys.exit(1)

num_gpus = torch.cuda.device_count()
print(f"âœ… æ£€æµ‹åˆ° {num_gpus} ä¸ªGPU")
for i in range(num_gpus):
    print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")

# åŠ è½½æ¨¡å‹
print("\nåŠ è½½æ¨¡å‹...")
print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")

try:
    from transformers import AutoModelForCausalLM, AutoTokenizer
    
    print("  åŠ è½½æ¨¡å‹...")
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="cuda:0",  # ä½¿ç”¨å•GPUé¿å…è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
        trust_remote_code=True
    ).eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    print("  åŠ è½½tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")
    
    # æ˜¾ç¤ºæ˜¾å­˜ä½¿ç”¨
    mem_allocated = torch.cuda.memory_allocated(0) / 1024**3
    print(f"\nå½“å‰æ˜¾å­˜ä½¿ç”¨: {mem_allocated:.2f} GB")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# è·å–æ‰€æœ‰å›¾ç‰‡
print("\nåŠ è½½å›¾ç‰‡åˆ—è¡¨...")
images_dir = os.path.join(data_root, 'images')
masks_dir = os.path.join(data_root, 'masks')

all_images = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]
print(f"æ€»å›¾ç‰‡æ•°: {len(all_images)}")

# éšæœºé€‰æ‹©10å¼ å›¾ç‰‡
random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ä¾¿å¤ç°
selected_images = random.sample(all_images, min(10, len(all_images)))
print(f"é€‰æ‹©å›¾ç‰‡æ•°: {len(selected_images)}")

# è¾…åŠ©å‡½æ•°
def load_mask_from_file(mask_path, image_shape):
    """ä»maskæ–‡ä»¶åŠ è½½æ©ç """
    if os.path.exists(mask_path):
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is not None:
            # ç¡®ä¿å°ºå¯¸åŒ¹é…
            if mask.shape != image_shape[:2]:
                mask = cv2.resize(mask, (image_shape[1], image_shape[0]))
            # äºŒå€¼åŒ–
            mask = (mask > 127).astype(np.uint8)
            return mask
    # å¦‚æœæ²¡æœ‰maskæ–‡ä»¶ï¼Œè¿”å›ç©ºæ©ç 
    return np.zeros(image_shape[:2], dtype=np.uint8)

def calculate_metrics(pred_mask, gt_mask, threshold=0.5):
    """è®¡ç®—åˆ†å‰²è¯„ä»·æŒ‡æ ‡"""
    pred_binary = (pred_mask > threshold).astype(np.uint8)
    gt_binary = (gt_mask > threshold).astype(np.uint8)
    
    TP = np.sum((pred_binary == 1) & (gt_binary == 1))
    FP = np.sum((pred_binary == 1) & (gt_binary == 0))
    FN = np.sum((pred_binary == 0) & (gt_binary == 1))
    TN = np.sum((pred_binary == 0) & (gt_binary == 0))
    
    dice = (2 * TP) / (2 * TP + FP + FN + 1e-8)
    iou = TP / (TP + FP + FN + 1e-8)
    precision = TP / (TP + FP + 1e-8)
    recall = TP / (TP + FN + 1e-8)
    specificity = TN / (TN + FP + 1e-8)
    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)
    
    return {
        'dice': dice,
        'iou': iou,
        'precision': precision,
        'recall': recall,
        'specificity': specificity,
        'accuracy': accuracy
    }

# å¼€å§‹é¢„æµ‹
print("\nå¼€å§‹é¢„æµ‹...")
print("-" * 80)

all_metrics = {
    'dice': [],
    'iou': [],
    'precision': [],
    'recall': [],
    'specificity': [],
    'accuracy': []
}

results = []

for idx, img_name in enumerate(tqdm(selected_images, desc="é¢„æµ‹è¿›åº¦")):
    try:
        # åŠ è½½å›¾åƒ
        img_path = os.path.join(images_dir, img_name)
        image = Image.open(img_path).convert('RGB')
        image_np = np.array(image)
        
        # åŠ è½½ground truth mask
        mask_name = img_name.replace('.jpg', '.png').replace('.png', '.png')
        mask_path = os.path.join(masks_dir, mask_name)
        gt_mask = load_mask_from_file(mask_path, image_np.shape)
        
        print(f"\næ ·æœ¬ {idx+1}: {img_name}")
        print(f"  å›¾åƒå°ºå¯¸: {image_np.shape}")
        print(f"  GTæ©ç : {'å­˜åœ¨' if os.path.exists(mask_path) else 'ä¸å­˜åœ¨'}")
        
        with torch.no_grad():
            try:
                # ä½¿ç”¨å®˜æ–¹demoçš„è°ƒç”¨æ–¹å¼
                text = "<image>Please segment the blood vessel in this image. [SEG]"
                
                result = model.predict_forward(
                    image=image,
                    text=text,
                    tokenizer=tokenizer,
                    processor=None
                )
                
                print("  âœ… é¢„æµ‹æˆåŠŸï¼")
                
                # æå–é¢„æµ‹æ©ç 
                if 'prediction_masks' in result and result['prediction_masks'] is not None and len(result['prediction_masks']) > 0:
                    pred_masks_list = result['prediction_masks'][0]
                    
                    if len(pred_masks_list) > 0:
                        pred_mask = pred_masks_list[0]
                        
                        if torch.is_tensor(pred_mask):
                            pred_mask = pred_mask.cpu().numpy()
                        
                        if pred_mask.shape != gt_mask.shape:
                            pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]))
                        
                        if pred_mask.max() > 1:
                            pred_mask = pred_mask / 255.0
                        
                        print(f"  é¢„æµ‹æ©ç å½¢çŠ¶: {pred_mask.shape}")
                        print(f"  é¢„æµ‹å€¼èŒƒå›´: [{pred_mask.min():.3f}, {pred_mask.max():.3f}]")
                    else:
                        print("  âš ï¸  é¢„æµ‹æ©ç åˆ—è¡¨ä¸ºç©º")
                        pred_mask = np.zeros_like(gt_mask, dtype=float)
                else:
                    print("  âš ï¸  æ¨¡å‹æœªè¿”å›é¢„æµ‹æ©ç ")
                    pred_mask = np.zeros_like(gt_mask, dtype=float)
                    
            except Exception as e:
                print(f"  âŒ é¢„æµ‹å¤±è´¥: {e}")
                pred_mask = np.zeros_like(gt_mask, dtype=float)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(pred_mask, gt_mask)
        
        print(f"  Dice: {metrics['dice']:.4f}, IoU: {metrics['iou']:.4f}")
        
        # è®°å½•æŒ‡æ ‡
        for key in all_metrics:
            all_metrics[key].append(metrics[key])
        
        # ä¿å­˜ç»“æœ
        results.append({
            'image': img_name,
            'metrics': metrics
        })
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        
        axes[0].imshow(image_np)
        axes[0].set_title('Original Image')
        axes[0].axis('off')
        
        axes[1].imshow(gt_mask, cmap='gray')
        axes[1].set_title('Ground Truth')
        axes[1].axis('off')
        
        axes[2].imshow(pred_mask, cmap='gray')
        axes[2].set_title(f'Model Prediction')
        axes[2].axis('off')
        
        axes[3].imshow(image_np)
        axes[3].imshow(pred_mask, alpha=0.5, cmap='Greens')
        axes[3].imshow(gt_mask, alpha=0.3, cmap='Reds')
        axes[3].set_title(f'Overlay\nDice: {metrics["dice"]:.4f}, IoU: {metrics["iou"]:.4f}')
        axes[3].axis('off')
        
        plt.tight_layout()
        vis_path = os.path.join(output_dir, 'visualizations', f'pred_{idx:02d}_{img_name}')
        plt.savefig(vis_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… å¯è§†åŒ–å·²ä¿å­˜")
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        continue

# æ±‡æ€»ç»“æœ
print("\n" + "=" * 80)
print("é¢„æµ‹ç»“æœæ±‡æ€»")
print("=" * 80)

for key in all_metrics:
    if len(all_metrics[key]) > 0:
        mean_val = np.mean(all_metrics[key])
        std_val = np.std(all_metrics[key])
        print(f"{key.upper():15s}: {mean_val:.4f} Â± {std_val:.4f}")

# ä¿å­˜ç»“æœ
results_json = {
    'dataset': 'Segment_DATA_Merged_512',
    'model_path': model_path,
    'num_samples': len(selected_images),
    'summary': {key: {'mean': float(np.mean(vals)), 'std': float(np.std(vals))} 
                for key, vals in all_metrics.items() if len(vals) > 0},
    'details': results
}

with open(os.path.join(output_dir, 'prediction_results.json'), 'w') as f:
    json.dump(results_json, f, indent=2)

print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {os.path.join(output_dir, 'prediction_results.json')}")
print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {os.path.join(output_dir, 'visualizations/')}")

print("\n" + "=" * 80)
print("ğŸ‰ é¢„æµ‹å®Œæˆï¼")
print("=" * 80)
